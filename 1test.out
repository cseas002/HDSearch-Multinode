Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Install HDSearch] ********************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

PLAY [Set Up Docker Curl] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]
ok: [node1]
ok: [node2]

PLAY [Make space to commit] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]
ok: [node2]
ok: [node1]

TASK [Make Space to Commit Image] **********************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node2] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:00.970837", "end": "2023-10-09 15:24:50.867586", "rc": 0, "start": "2023-10-09 15:24:49.896749", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\n\"docker rmi\" requires at least 1 argument.\nSee 'docker rmi --help'.\n\nUsage:  docker rmi [OPTIONS] IMAGE [IMAGE...]\n\nRemove one or more images\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "\"docker rmi\" requires at least 1 argument.", "See 'docker rmi --help'.", "", "Usage:  docker rmi [OPTIONS] IMAGE [IMAGE...]", "", "Remove one or more images", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:00.978275", "end": "2023-10-09 15:24:50.852536", "rc": 0, "start": "2023-10-09 15:24:49.874261", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\n\"docker rmi\" requires at least 1 argument.\nSee 'docker rmi --help'.\n\nUsage:  docker rmi [OPTIONS] IMAGE [IMAGE...]\n\nRemove one or more images\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "\"docker rmi\" requires at least 1 argument.", "See 'docker rmi --help'.", "", "Usage:  docker rmi [OPTIONS] IMAGE [IMAGE...]", "", "Remove one or more images", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "", "stdout_lines": []}
changed: [node0] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:00.999487", "end": "2023-10-09 15:24:50.869194", "rc": 0, "start": "2023-10-09 15:24:49.869707", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\n\"docker rmi\" requires at least 1 argument.\nSee 'docker rmi --help'.\n\nUsage:  docker rmi [OPTIONS] IMAGE [IMAGE...]\n\nRemove one or more images\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "\"docker rmi\" requires at least 1 argument.", "See 'docker rmi --help'.", "", "Usage:  docker rmi [OPTIONS] IMAGE [IMAGE...]", "", "Remove one or more images", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "", "stdout_lines": []}

PLAY [Install Profiler Dep] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Set profiler Hosts] ******************************************************
changed: [node1] => {"ansible_job_id": "65561418831.18638", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/65561418831.18638", "started": 1}
changed: [node2] => {"ansible_job_id": "24769950032.18736", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/24769950032.18736", "started": 1}

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node0]
ok: [node1]

TASK [Leave Swarm] *************************************************************
changed: [node1] => {"ansible_job_id": "668299744591.18764", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/668299744591.18764", "started": 1}
changed: [node0] => {"ansible_job_id": "493254381516.19384", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/493254381516.19384", "started": 1}
changed: [node2] => {"ansible_job_id": "788168061097.18862", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/788168061097.18862", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Init Master] *************************************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": "sudo docker swarm init --advertise-addr 10.10.1.1", "delta": "0:00:00.602885", "end": "2023-10-09 15:25:03.251452", "rc": 0, "start": "2023-10-09 15:25:02.648567", "stderr": "", "stderr_lines": [], "stdout": "Swarm initialized: current node (1ahv9zlvr48dj2yz6ba57hm3v) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-1d3bwjkrmmkendteqix327x6f3w50qq3fcx7zpp8a0v3b92b3x-asxo0r3821mvy9edf3pvsnac2 10.10.1.1:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.", "stdout_lines": ["Swarm initialized: current node (1ahv9zlvr48dj2yz6ba57hm3v) is now a manager.", "", "To add a worker to this swarm, run the following command:", "", "    docker swarm join --token SWMTKN-1-1d3bwjkrmmkendteqix327x6f3w50qq3fcx7zpp8a0v3b92b3x-asxo0r3821mvy9edf3pvsnac2 10.10.1.1:2377", "", "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions."]}

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Init Workers] ************************************************************
changed: [node1] => {"ansible_job_id": "70950936213.18908", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/70950936213.18908", "started": 1}
changed: [node2] => {"ansible_job_id": "358841794871.19006", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/358841794871.19006", "started": 1}

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Set uncore frequency] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Load msr kernel module] **************************************************
changed: [node1] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.007756", "end": "2023-10-09 15:25:10.175200", "rc": 0, "start": "2023-10-09 15:25:10.167444", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node2] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.008080", "end": "2023-10-09 15:25:10.201114", "rc": 0, "start": "2023-10-09 15:25:10.193034", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

TASK [Set uncore freq] *********************************************************
changed: [node2] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.007197", "end": "2023-10-09 15:25:10.483525", "rc": 0, "start": "2023-10-09 15:25:10.476328", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.007219", "end": "2023-10-09 15:25:10.485869", "rc": 0, "start": "2023-10-09 15:25:10.478650", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
node1                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_client
Creating service microsuite_bucket
Creating service microsuite_midtier
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 0", "delta": "0:15:34.759968", "end": "2023-10-09 15:41:09.363999", "rc": 0, "start": "2023-10-09 15:25:34.604031", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 0 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 0 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n20140\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"703489670073.20600\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/703489670073.20600\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nok: [node2] => {\"ansible_job_id\": \"703489670073.20600\", \"changed\": false, \"finished\": 0, \"started\": 1}\n\nPLAY [Kill remote profiler] ****************************************************\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"221147883677.20590\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/221147883677.20590\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nok: [node1] => {\"ansible_job_id\": \"221147883677.20590\", \"changed\": false, \"finished\": 0, \"started\": 1}\n\nPLAY [Kill remote profiler] ****************************************************\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "20140", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"703489670073.20600\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/703489670073.20600\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "ok: [node2] => {\"ansible_job_id\": \"703489670073.20600\", \"changed\": false, \"finished\": 0, \"started\": 1}", "", "PLAY [Kill remote profiler] ****************************************************", "", "PLAY RECAP *********************************************************************", "node2                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"221147883677.20590\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/221147883677.20590\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "ok: [node1] => {\"ansible_job_id\": \"221147883677.20590\", \"changed\": false, \"finished\": 0, \"started\": 1}", "", "PLAY [Kill remote profiler] ****************************************************", "", "PLAY RECAP *********************************************************************", "node1                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node2] => {"ansible_job_id": "233515877660.20812", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/233515877660.20812", "started": 1}
changed: [node1] => {"ansible_job_id": "552927171886.20797", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/552927171886.20797", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:40.892714", "end": "2023-10-09 15:42:57.589531", "rc": 0, "start": "2023-10-09 15:41:16.696817", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-0/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-0/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.8] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 1 
INFO:root:# Responses: 1 
INFO:root:Achieved QPS: 0.00833333 
INFO:root:Average Response Time(ms): 6.838 
INFO:root:6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 
INFO:root: Total response time 
INFO:root:6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 6.838 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 
INFO:root: Unpack loadgen request time 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 
INFO:root: Get point ids time 
INFO:root:0.311 0.311 0.311 0.311 0.311 0.311 0.311 0.311 0.311 0.311 0.311 0.311 
INFO:root: Total time taken by index server: 
INFO:root:1.585 1.585 1.585 1.585 1.585 1.585 1.585 1.585 1.585 1.585 1.585 1.585 Average Index Time(ms): 1.585 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.903 4.903 4.903 4.903 4.903 4.903 4.903 4.903 4.903 4.903 4.903 4.903 Average Bucket Time(ms): 4.903 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 
INFO:root: Calculate knn time 
INFO:root:0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 
INFO:root: Pack index response time 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 0.055 
INFO:root: Unpack index response time 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-0/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-0/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 0", "delta": "0:01:31.113911", "end": "2023-10-09 15:45:59.025401", "rc": 0, "start": "2023-10-09 15:44:27.911490", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 0 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 0 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n21259\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"795284951916.21709\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/795284951916.21709\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"795284951916.21709\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"21259\"], \"delta\": \"0:00:00.123814\", \"end\": \"2023-10-09 15:45:53.333357\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 15:45:53.209543\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"642251876428.21744\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/642251876428.21744\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"642251876428.21744\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"21256\"], \"delta\": \"0:00:00.123555\", \"end\": \"2023-10-09 15:45:58.169963\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 15:45:58.046408\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "21259", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"795284951916.21709\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/795284951916.21709\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"795284951916.21709\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"21259\"], \"delta\": \"0:00:00.123814\", \"end\": \"2023-10-09 15:45:53.333357\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 15:45:53.209543\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"642251876428.21744\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/642251876428.21744\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"642251876428.21744\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"21256\"], \"delta\": \"0:00:00.123555\", \"end\": \"2023-10-09 15:45:58.169963\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 15:45:58.046408\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "509057696791.21949", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/509057696791.21949", "started": 1}
changed: [node2] => {"ansible_job_id": "266496168172.21914", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/266496168172.21914", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:42.277569", "end": "2023-10-09 15:47:47.683702", "rc": 0, "start": "2023-10-09 15:46:05.406133", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-0/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-0/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 5 
INFO:root:# Responses: 5 
INFO:root:Achieved QPS: 0.0416667 
INFO:root:Average Response Time(ms): 6.6032 
INFO:root:6.244 6.454 6.454 6.609 6.609 6.782 6.782 6.927 6.927 6.927 6.927 6.927 6.244 6.454 6.454 6.609 6.609 6.782 6.782 6.927 6.927 6.927 6.927 6.927 
INFO:root: Total response time 
INFO:root:6.244 6.454 6.454 6.609 6.609 6.782 6.782 6.927 6.927 6.927 6.927 6.927 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.61 0.613 0.613 0.619 0.619 0.622 0.622 0.652 0.652 0.652 0.652 0.652 
INFO:root: Unpack loadgen request time 0.053 0.057 0.057 0.058 0.058 0.059 0.059 0.063 0.063 0.063 0.063 0.063 
INFO:root: Get point ids time 
INFO:root:0.114 0.152 0.152 0.177 0.177 0.18 0.18 0.313 0.313 0.313 0.313 0.313 
INFO:root: Total time taken by index server: 
INFO:root:1.292 1.294 1.294 1.327 1.327 1.36 1.36 1.53 1.53 1.53 1.53 1.53 Average Index Time(ms): 1.3606 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.333 4.791 4.791 4.867 4.867 5.038 5.038 5.132 5.132 5.132 5.132 5.132 Average Bucket Time(ms): 4.8322 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.022 0.023 0.023 0.025 0.025 0.029 0.029 0.029 0.029 0.029 0.029 0.029 
INFO:root: Calculate knn time 
INFO:root:0.043 0.079 0.079 0.144 0.144 0.148 0.148 0.15 0.15 0.15 0.15 0.15 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0 0 0 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.032 0.049 0.049 0.05 0.05 0.054 0.054 0.055 0.055 0.055 0.055 0.055 
INFO:root: Pack index response time 0.032 0.049 0.049 0.05 0.05 0.054 0.054 0.055 0.055 0.055 0.055 0.055 
INFO:root: Unpack index response time 0.003 0.003 0.003 0.003 0.003 0.004 0.004 0.004 0.004 0.004 0.004 0.004 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-0/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-0/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_client
Creating service microsuite_bucket
Creating service microsuite_midtier
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 0", "delta": "0:01:30.109846", "end": "2023-10-09 15:50:47.027330", "rc": 0, "start": "2023-10-09 15:49:16.917484", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 0 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 0 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n22371\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"54480955145.22812\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/54480955145.22812\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"54480955145.22812\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"22371\"], \"delta\": \"0:00:00.120455\", \"end\": \"2023-10-09 15:50:41.262446\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 15:50:41.141991\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"626091625377.22942\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/626091625377.22942\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"626091625377.22942\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"22455\"], \"delta\": \"0:00:00.124070\", \"end\": \"2023-10-09 15:50:46.126444\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 15:50:46.002374\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "22371", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"54480955145.22812\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/54480955145.22812\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"54480955145.22812\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"22371\"], \"delta\": \"0:00:00.120455\", \"end\": \"2023-10-09 15:50:41.262446\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 15:50:41.141991\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"626091625377.22942\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/626091625377.22942\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"626091625377.22942\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"22455\"], \"delta\": \"0:00:00.124070\", \"end\": \"2023-10-09 15:50:46.126444\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 15:50:46.002374\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node2] => {"ansible_job_id": "731039302742.23023", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/731039302742.23023", "started": 1}
changed: [node1] => {"ansible_job_id": "994754089997.23155", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/994754089997.23155", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:41.010233", "end": "2023-10-09 15:52:35.410290", "rc": 0, "start": "2023-10-09 15:50:54.400057", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-0/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-0/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 12 
INFO:root:# Responses: 11 
INFO:root:Achieved QPS: 0.0916667 
INFO:root:Average Response Time(ms): 6.64164 
INFO:root:6.143 6.471 6.567 6.659 6.697 6.721 6.807 7.029 7.147 7.179 7.179 7.179 6.143 6.471 6.567 6.659 6.697 6.721 6.807 7.029 7.147 7.179 7.179 7.179 
INFO:root: Total response time 
INFO:root:6.143 6.471 6.567 6.659 6.697 6.721 6.807 7.029 7.147 7.179 7.179 7.179 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.597 0.599 0.606 0.61 0.612 0.617 0.618 0.62 0.621 0.638 0.638 0.638 
INFO:root: Unpack loadgen request time 0.054 0.055 0.055 0.056 0.058 0.058 0.06 0.062 0.062 0.062 0.062 0.062 
INFO:root: Get point ids time 
INFO:root:0.177 0.178 0.2 0.236 0.282 0.292 0.311 0.323 0.407 0.439 0.439 0.439 
INFO:root: Total time taken by index server: 
INFO:root:1.295 1.36 1.373 1.39 1.39 1.416 1.564 1.577 1.586 1.821 1.821 1.821 Average Index Time(ms): 1.45918 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.082 4.66 4.804 4.863 4.936 4.944 4.971 5.108 5.134 5.144 5.144 5.144 Average Bucket Time(ms): 4.78845 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.009 0.023 0.026 0.026 0.026 0.026 0.028 0.028 0.029 0.033 0.033 0.033 
INFO:root: Calculate knn time 
INFO:root:0.115 0.14 0.152 0.172 0.175 0.175 0.179 0.179 0.18 0.192 0.192 0.192 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.034 0.035 0.048 0.05 0.05 0.052 0.052 0.053 0.053 0.07 0.07 0.07 
INFO:root: Pack index response time 0.034 0.035 0.048 0.05 0.05 0.052 0.052 0.053 0.053 0.07 0.07 0.07 
INFO:root: Unpack index response time 0.003 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.005 0.008 0.008 0.008 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-0/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-0/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]
ok: [node2]
ok: [node1]

TASK [Leave Swarm] *************************************************************
changed: [node2] => {"ansible_job_id": "715181663825.23446", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/715181663825.23446", "started": 1}
changed: [node1] => {"ansible_job_id": "88071837652.23555", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/88071837652.23555", "started": 1}
changed: [node0] => {"ansible_job_id": "436580512504.26356", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/436580512504.26356", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Install HDSearch] ********************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

PLAY [Set Up Docker Curl] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

PLAY [Make space to commit] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]
ok: [node0]

TASK [Make Space to Commit Image] **********************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node2] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.482334", "end": "2023-10-09 15:53:55.402575", "rc": 0, "start": "2023-10-09 15:53:50.920241", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node1] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.987966", "end": "2023-10-09 15:53:55.906233", "rc": 0, "start": "2023-10-09 15:53:50.918267", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node0] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:05.094396", "end": "2023-10-09 15:53:56.014238", "rc": 0, "start": "2023-10-09 15:53:50.919842", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}

PLAY [Install Profiler Dep] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Set profiler Hosts] ******************************************************
changed: [node2] => {"ansible_job_id": "467310252869.24186", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/467310252869.24186", "started": 1}
changed: [node1] => {"ansible_job_id": "928911819743.24304", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/928911819743.24304", "started": 1}

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

TASK [Leave Swarm] *************************************************************
changed: [node1] => {"ansible_job_id": "459685350033.24437", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/459685350033.24437", "started": 1}
changed: [node0] => {"ansible_job_id": "700783974718.27152", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/700783974718.27152", "started": 1}
changed: [node2] => {"ansible_job_id": "939261822113.24318", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/939261822113.24318", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Init Master] *************************************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": "sudo docker swarm init --advertise-addr 10.10.1.1", "delta": "0:00:00.602736", "end": "2023-10-09 15:54:06.488349", "rc": 0, "start": "2023-10-09 15:54:05.885613", "stderr": "", "stderr_lines": [], "stdout": "Swarm initialized: current node (mrjagw1ru1x4s7eldrmc6jf1l) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-2d40hv99xe55fcor9dmo857wpjj7ctmrh70teiffvp0fl8iq1p-7f8gohfe87yt6ysjdtxajqhw8 10.10.1.1:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.", "stdout_lines": ["Swarm initialized: current node (mrjagw1ru1x4s7eldrmc6jf1l) is now a manager.", "", "To add a worker to this swarm, run the following command:", "", "    docker swarm join --token SWMTKN-1-2d40hv99xe55fcor9dmo857wpjj7ctmrh70teiffvp0fl8iq1p-7f8gohfe87yt6ysjdtxajqhw8 10.10.1.1:2377", "", "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions."]}

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Init Workers] ************************************************************
changed: [node1] => {"ansible_job_id": "134829327614.24572", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/134829327614.24572", "started": 1}
changed: [node2] => {"ansible_job_id": "668493978997.24451", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/668493978997.24451", "started": 1}

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Set uncore frequency] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Load msr kernel module] **************************************************
changed: [node1] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.008057", "end": "2023-10-09 15:54:14.316229", "rc": 0, "start": "2023-10-09 15:54:14.308172", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node2] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.007958", "end": "2023-10-09 15:54:14.334861", "rc": 0, "start": "2023-10-09 15:54:14.326903", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

TASK [Set uncore freq] *********************************************************
changed: [node2] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.006607", "end": "2023-10-09 15:54:14.636017", "rc": 0, "start": "2023-10-09 15:54:14.629410", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.006674", "end": "2023-10-09 15:54:14.635086", "rc": 0, "start": "2023-10-09 15:54:14.628412", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
node1                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 1", "delta": "0:15:30.122441", "end": "2023-10-09 16:10:09.619567", "rc": 0, "start": "2023-10-09 15:54:39.497126", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 1 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 1 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n25317\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"138067624947.25770\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/138067624947.25770\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"138067624947.25770\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"25317\"], \"delta\": \"0:00:00.120600\", \"end\": \"2023-10-09 16:10:03.899790\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:10:03.779190\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"233085120964.26012\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/233085120964.26012\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"233085120964.26012\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"25474\"], \"delta\": \"0:00:00.121848\", \"end\": \"2023-10-09 16:10:08.773502\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:10:08.651654\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "25317", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"138067624947.25770\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/138067624947.25770\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"138067624947.25770\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"25317\"], \"delta\": \"0:00:00.120600\", \"end\": \"2023-10-09 16:10:03.899790\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:10:03.779190\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"233085120964.26012\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/233085120964.26012\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"233085120964.26012\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"25474\"], \"delta\": \"0:00:00.121848\", \"end\": \"2023-10-09 16:10:08.773502\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:10:08.651654\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "280036584122.26223", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/280036584122.26223", "started": 1}
changed: [node2] => {"ansible_job_id": "948422292270.25984", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/948422292270.25984", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:42.214852", "end": "2023-10-09 16:11:59.218365", "rc": 0, "start": "2023-10-09 16:10:17.003513", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-1/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-1/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.2] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 1 
INFO:root:# Responses: 1 
INFO:root:Achieved QPS: 0.00833333 
INFO:root:Average Response Time(ms): 11.483 
INFO:root:11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 
INFO:root: Total response time 
INFO:root:11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 11.483 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.647 0.647 0.647 0.647 0.647 0.647 0.647 0.647 0.647 0.647 0.647 0.647 
INFO:root: Unpack loadgen request time 0.058 0.058 0.058 0.058 0.058 0.058 0.058 0.058 0.058 0.058 0.058 0.058 
INFO:root: Get point ids time 
INFO:root:0.313 0.313 0.313 0.313 0.313 0.313 0.313 0.313 0.313 0.313 0.313 0.313 
INFO:root: Total time taken by index server: 
INFO:root:1.626 1.626 1.626 1.626 1.626 1.626 1.626 1.626 1.626 1.626 1.626 1.626 Average Index Time(ms): 1.626 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:9.543 9.543 9.543 9.543 9.543 9.543 9.543 9.543 9.543 9.543 9.543 9.543 Average Bucket Time(ms): 9.543 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.032 0.032 0.032 0.032 0.032 0.032 0.032 0.032 0.032 0.032 0.032 0.032 
INFO:root: Calculate knn time 
INFO:root:0.177 0.177 0.177 0.177 0.177 0.177 0.177 0.177 0.177 0.177 0.177 0.177 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 
INFO:root: Pack index response time 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 
INFO:root: Unpack index response time 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-1/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-1/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 1", "delta": "0:01:27.730365", "end": "2023-10-09 16:14:57.715361", "rc": 0, "start": "2023-10-09 16:13:29.984996", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 1 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 1 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n26434\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"411053434265.26874\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/411053434265.26874\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"411053434265.26874\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"26434\"], \"delta\": \"0:00:00.124497\", \"end\": \"2023-10-09 16:14:52.020766\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:14:51.896269\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"675688615156.27204\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/675688615156.27204\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"675688615156.27204\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"26709\"], \"delta\": \"0:00:00.121515\", \"end\": \"2023-10-09 16:14:56.871805\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:14:56.750290\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "26434", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"411053434265.26874\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/411053434265.26874\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"411053434265.26874\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"26434\"], \"delta\": \"0:00:00.124497\", \"end\": \"2023-10-09 16:14:52.020766\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:14:51.896269\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"675688615156.27204\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/675688615156.27204\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"675688615156.27204\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"26709\"], \"delta\": \"0:00:00.121515\", \"end\": \"2023-10-09 16:14:56.871805\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:14:56.750290\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "144974381194.27414", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/144974381194.27414", "started": 1}
changed: [node2] => {"ansible_job_id": "303088874628.27089", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/303088874628.27089", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:42.219111", "end": "2023-10-09 16:16:46.428916", "rc": 0, "start": "2023-10-09 16:15:04.209805", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-1/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-1/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 5 
INFO:root:# Responses: 5 
INFO:root:Achieved QPS: 0.0416667 
INFO:root:Average Response Time(ms): 7.8096 
INFO:root:6.283 6.589 6.589 6.985 6.985 9.084 9.084 10.107 10.107 10.107 10.107 10.107 6.283 6.589 6.589 6.985 6.985 9.084 9.084 10.107 10.107 10.107 10.107 10.107 
INFO:root: Total response time 
INFO:root:6.283 6.589 6.589 6.985 6.985 9.084 9.084 10.107 10.107 10.107 10.107 10.107 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.61 0.61 0.61 0.612 0.612 0.631 0.631 0.633 0.633 0.633 0.633 0.633 
INFO:root: Unpack loadgen request time 0.054 0.062 0.062 0.063 0.063 0.064 0.064 0.065 0.065 0.065 0.065 0.065 
INFO:root: Get point ids time 
INFO:root:0.137 0.159 0.159 0.183 0.183 0.243 0.243 0.328 0.328 0.328 0.328 0.328 
INFO:root: Total time taken by index server: 
INFO:root:1.269 1.386 1.386 1.389 1.389 1.402 1.402 1.72 1.72 1.72 1.72 1.72 Average Index Time(ms): 1.4332 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.415 4.778 4.778 5.04 5.04 7.315 7.315 8.499 8.499 8.499 8.499 8.499 Average Bucket Time(ms): 6.0094 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.023 0.024 0.024 0.029 0.029 0.029 0.029 0.032 0.032 0.032 0.032 0.032 
INFO:root: Calculate knn time 
INFO:root:0.042 0.148 0.148 0.151 0.151 0.156 0.156 0.177 0.177 0.177 0.177 0.177 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.003 0.003 0.003 0.003 0.003 0.003 0.003 
INFO:root: Unpack bucket response time 0 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.033 0.036 0.036 0.044 0.044 0.054 0.054 0.066 0.066 0.066 0.066 0.066 
INFO:root: Pack index response time 0.033 0.036 0.036 0.044 0.044 0.054 0.054 0.066 0.066 0.066 0.066 0.066 
INFO:root: Unpack index response time 0.003 0.003 0.003 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-1/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-1/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_client
Creating service microsuite_bucket
Creating service microsuite_midtier
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 1", "delta": "0:01:31.113426", "end": "2023-10-09 16:19:46.638088", "rc": 0, "start": "2023-10-09 16:18:15.524662", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 1 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 1 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n27547\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"127476394891.27987\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/127476394891.27987\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"127476394891.27987\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"27547\"], \"delta\": \"0:00:00.122551\", \"end\": \"2023-10-09 16:19:40.916806\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:19:40.794255\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"423196655840.28391\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/423196655840.28391\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"423196655840.28391\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"27897\"], \"delta\": \"0:00:00.124418\", \"end\": \"2023-10-09 16:19:45.780011\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:19:45.655593\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "27547", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"127476394891.27987\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/127476394891.27987\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"127476394891.27987\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"27547\"], \"delta\": \"0:00:00.122551\", \"end\": \"2023-10-09 16:19:40.916806\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:19:40.794255\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"423196655840.28391\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/423196655840.28391\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"423196655840.28391\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"1\", \"-t\", \"27897\"], \"delta\": \"0:00:00.124418\", \"end\": \"2023-10-09 16:19:45.780011\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:19:45.655593\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "755177869969.28596", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/755177869969.28596", "started": 1}
changed: [node2] => {"ansible_job_id": "694339840894.28193", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/694339840894.28193", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:42.285903", "end": "2023-10-09 16:21:36.426552", "rc": 0, "start": "2023-10-09 16:19:54.140649", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-1/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-1/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.8] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 12 
INFO:root:# Responses: 11 
INFO:root:Achieved QPS: 0.0916667 
INFO:root:Average Response Time(ms): 6.73145 
INFO:root:6.489 6.657 6.679 6.734 6.755 6.811 6.841 6.906 7.034 7.213 7.213 7.213 6.489 6.657 6.679 6.734 6.755 6.811 6.841 6.906 7.034 7.213 7.213 7.213 
INFO:root: Total response time 
INFO:root:6.489 6.657 6.679 6.734 6.755 6.811 6.841 6.906 7.034 7.213 7.213 7.213 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.581 0.588 0.596 0.597 0.599 0.602 0.605 0.614 0.617 0.635 0.635 0.635 
INFO:root: Unpack loadgen request time 0.055 0.059 0.059 0.06 0.06 0.06 0.061 0.061 0.062 0.063 0.063 0.063 
INFO:root: Get point ids time 
INFO:root:0.177 0.206 0.215 0.242 0.282 0.295 0.314 0.332 0.402 0.442 0.442 0.442 
INFO:root: Total time taken by index server: 
INFO:root:1.373 1.378 1.386 1.4 1.408 1.507 1.526 1.583 1.616 1.707 1.707 1.707 Average Index Time(ms): 1.47191 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.712 4.856 4.895 4.9 4.905 4.943 4.995 5.094 5.303 5.376 5.376 5.376 Average Bucket Time(ms): 4.92664 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.019 0.025 0.026 0.026 0.027 0.028 0.028 0.029 0.031 0.034 0.034 0.034 
INFO:root: Calculate knn time 
INFO:root:0.042 0.043 0.044 0.066 0.138 0.144 0.144 0.15 0.158 0.176 0.176 0.176 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0 0 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.049 0.05 0.051 0.051 0.051 0.052 0.052 0.054 0.054 0.068 0.068 0.068 
INFO:root: Pack index response time 0.049 0.05 0.051 0.051 0.051 0.052 0.052 0.054 0.054 0.068 0.068 0.068 
INFO:root: Unpack index response time 0.003 0.003 0.003 0.003 0.003 0.004 0.004 0.004 0.004 0.004 0.004 0.004 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-1/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-1/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]
ok: [node1]
ok: [node2]

TASK [Leave Swarm] *************************************************************
changed: [node1] => {"ansible_job_id": "440892757338.29077", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/440892757338.29077", "started": 1}
changed: [node2] => {"ansible_job_id": "363196809284.28635", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/363196809284.28635", "started": 1}
changed: [node0] => {"ansible_job_id": "544871982869.33936", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/544871982869.33936", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Install HDSearch] ********************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

PLAY [Set Up Docker Curl] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

PLAY [Make space to commit] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

TASK [Make Space to Commit Image] **********************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node1] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.487999", "end": "2023-10-09 16:22:55.682764", "rc": 0, "start": "2023-10-09 16:22:51.194765", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node2] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.770981", "end": "2023-10-09 16:22:55.977558", "rc": 0, "start": "2023-10-09 16:22:51.206577", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node0] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:05.049019", "end": "2023-10-09 16:22:56.243372", "rc": 0, "start": "2023-10-09 16:22:51.194353", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}

PLAY [Install Profiler Dep] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Set profiler Hosts] ******************************************************
changed: [node1] => {"ansible_job_id": "89798931914.29814", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/89798931914.29814", "started": 1}
changed: [node2] => {"ansible_job_id": "347913729724.29377", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/347913729724.29377", "started": 1}

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]
ok: [node1]
ok: [node2]

TASK [Leave Swarm] *************************************************************
changed: [node1] => {"ansible_job_id": "300174138860.29950", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/300174138860.29950", "started": 1}
changed: [node2] => {"ansible_job_id": "997458621365.29509", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/997458621365.29509", "started": 1}
changed: [node0] => {"ansible_job_id": "50415175255.34732", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/50415175255.34732", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Init Master] *************************************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": "sudo docker swarm init --advertise-addr 10.10.1.1", "delta": "0:00:00.609033", "end": "2023-10-09 16:23:09.692893", "rc": 0, "start": "2023-10-09 16:23:09.083860", "stderr": "", "stderr_lines": [], "stdout": "Swarm initialized: current node (aaip42z8h4pyal404pg9qduaa) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-5xpgnhrl2sldfoa97sv7qggzmhgaq83azthbm8rwzaob30y19y-072hu29tj0maz87rdxbnkyku2 10.10.1.1:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.", "stdout_lines": ["Swarm initialized: current node (aaip42z8h4pyal404pg9qduaa) is now a manager.", "", "To add a worker to this swarm, run the following command:", "", "    docker swarm join --token SWMTKN-1-5xpgnhrl2sldfoa97sv7qggzmhgaq83azthbm8rwzaob30y19y-072hu29tj0maz87rdxbnkyku2 10.10.1.1:2377", "", "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions."]}

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Init Workers] ************************************************************
changed: [node2] => {"ansible_job_id": "557740961316.29643", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/557740961316.29643", "started": 1}
changed: [node1] => {"ansible_job_id": "221028184780.30086", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/221028184780.30086", "started": 1}

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Set uncore frequency] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Load msr kernel module] **************************************************
changed: [node1] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.008289", "end": "2023-10-09 16:23:17.597428", "rc": 0, "start": "2023-10-09 16:23:17.589139", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node2] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.007897", "end": "2023-10-09 16:23:17.605101", "rc": 0, "start": "2023-10-09 16:23:17.597204", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

TASK [Set uncore freq] *********************************************************
changed: [node2] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.006675", "end": "2023-10-09 16:23:17.915497", "rc": 0, "start": "2023-10-09 16:23:17.908822", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.007061", "end": "2023-10-09 16:23:17.922089", "rc": 0, "start": "2023-10-09 16:23:17.915028", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
node1                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 2", "delta": "0:15:25.334091", "end": "2023-10-09 16:39:07.032775", "rc": 0, "start": "2023-10-09 16:23:41.698684", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 2 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 2 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n30497\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"585673440820.30938\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/585673440820.30938\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"585673440820.30938\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"30497\"], \"delta\": \"0:00:00.121786\", \"end\": \"2023-10-09 16:39:01.307885\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:39:01.186099\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"813298440833.31632\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/813298440833.31632\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"813298440833.31632\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"31133\"], \"delta\": \"0:00:00.120451\", \"end\": \"2023-10-09 16:39:06.156985\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:39:06.036534\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "30497", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"585673440820.30938\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/585673440820.30938\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"585673440820.30938\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"30497\"], \"delta\": \"0:00:00.121786\", \"end\": \"2023-10-09 16:39:01.307885\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:39:01.186099\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"813298440833.31632\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/813298440833.31632\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"813298440833.31632\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"31133\"], \"delta\": \"0:00:00.120451\", \"end\": \"2023-10-09 16:39:06.156985\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:39:06.036534\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "473904835869.31836", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/473904835869.31836", "started": 1}
changed: [node2] => {"ansible_job_id": "139621658974.31144", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/139621658974.31144", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:39.544084", "end": "2023-10-09 16:40:55.201676", "rc": 0, "start": "2023-10-09 16:39:15.657592", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-2/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-2/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 1 
INFO:root:# Responses: 1 
INFO:root:Achieved QPS: 0.00833333 
INFO:root:Average Response Time(ms): 7.15 
INFO:root:7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 
INFO:root: Total response time 
INFO:root:7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 7.15 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.625 0.625 0.625 0.625 0.625 0.625 0.625 0.625 0.625 0.625 0.625 0.625 
INFO:root: Unpack loadgen request time 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 
INFO:root: Get point ids time 
INFO:root:0.229 0.229 0.229 0.229 0.229 0.229 0.229 0.229 0.229 0.229 0.229 0.229 
INFO:root: Total time taken by index server: 
INFO:root:1.467 1.467 1.467 1.467 1.467 1.467 1.467 1.467 1.467 1.467 1.467 1.467 Average Index Time(ms): 1.467 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:5.242 5.242 5.242 5.242 5.242 5.242 5.242 5.242 5.242 5.242 5.242 5.242 Average Bucket Time(ms): 5.242 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 0.027 
INFO:root: Calculate knn time 
INFO:root:0.142 0.142 0.142 0.142 0.142 0.142 0.142 0.142 0.142 0.142 0.142 0.142 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 
INFO:root: Pack index response time 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 
INFO:root: Unpack index response time 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-2/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-2/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 2", "delta": "0:01:33.403371", "end": "2023-10-09 16:43:58.020912", "rc": 0, "start": "2023-10-09 16:42:24.617541", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 2 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 2 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n31615\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"716391452174.32050\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/716391452174.32050\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"716391452174.32050\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"31615\"], \"delta\": \"0:00:00.121800\", \"end\": \"2023-10-09 16:43:52.304496\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:43:52.182696\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"688887078309.32811\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/688887078309.32811\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"688887078309.32811\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"32307\"], \"delta\": \"0:00:00.124998\", \"end\": \"2023-10-09 16:43:57.157686\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:43:57.032688\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "31615", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"716391452174.32050\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/716391452174.32050\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"716391452174.32050\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"31615\"], \"delta\": \"0:00:00.121800\", \"end\": \"2023-10-09 16:43:52.304496\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:43:52.182696\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"688887078309.32811\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/688887078309.32811\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"688887078309.32811\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"32307\"], \"delta\": \"0:00:00.124998\", \"end\": \"2023-10-09 16:43:57.157686\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:43:57.032688\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "614655655615.33015", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/614655655615.33015", "started": 1}
changed: [node2] => {"ansible_job_id": "529027770395.32261", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/529027770395.32261", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:42.377071", "end": "2023-10-09 16:45:47.781857", "rc": 0, "start": "2023-10-09 16:44:05.404786", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-2/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-2/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 5 
INFO:root:# Responses: 5 
INFO:root:Achieved QPS: 0.0416667 
INFO:root:Average Response Time(ms): 6.7376 
INFO:root:6.506 6.585 6.585 6.827 6.827 6.866 6.866 6.904 6.904 6.904 6.904 6.904 6.506 6.585 6.585 6.827 6.827 6.866 6.866 6.904 6.904 6.904 6.904 6.904 
INFO:root: Total response time 
INFO:root:6.506 6.585 6.585 6.827 6.827 6.866 6.866 6.904 6.904 6.904 6.904 6.904 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.617 0.619 0.619 0.62 0.62 0.626 0.626 0.639 0.639 0.639 0.639 0.639 
INFO:root: Unpack loadgen request time 0.057 0.061 0.061 0.063 0.063 0.064 0.064 0.064 0.064 0.064 0.064 0.064 
INFO:root: Get point ids time 
INFO:root:0.172 0.185 0.185 0.241 0.241 0.322 0.322 0.343 0.343 0.343 0.343 0.343 
INFO:root: Total time taken by index server: 
INFO:root:1.342 1.375 1.375 1.444 1.444 1.511 1.511 1.585 1.585 1.585 1.585 1.585 Average Index Time(ms): 1.4514 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.749 4.768 4.768 4.886 4.886 4.913 4.913 5.061 5.061 5.061 5.061 5.061 Average Bucket Time(ms): 4.8754 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.009 0.023 0.023 0.026 0.026 0.027 0.027 0.029 0.029 0.029 0.029 0.029 
INFO:root: Calculate knn time 
INFO:root:0.041 0.042 0.042 0.042 0.042 0.148 0.148 0.167 0.167 0.167 0.167 0.167 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.037 0.037 0.037 0.052 0.052 0.059 0.059 0.061 0.061 0.061 0.061 0.061 
INFO:root: Pack index response time 0.037 0.037 0.037 0.052 0.052 0.059 0.059 0.061 0.061 0.061 0.061 0.061 
INFO:root: Unpack index response time 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-2/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-2/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 2", "delta": "0:01:32.174106", "end": "2023-10-09 16:48:50.709100", "rc": 0, "start": "2023-10-09 16:47:18.534994", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 2 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 2 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n32720\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"814418344814.33156\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/814418344814.33156\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"814418344814.33156\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"32720\"], \"delta\": \"0:00:00.107249\", \"end\": \"2023-10-09 16:48:45.006785\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:48:44.899536\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"495818061841.34008\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/495818061841.34008\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"495818061841.34008\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"33503\"], \"delta\": \"0:00:00.122563\", \"end\": \"2023-10-09 16:48:49.832254\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:48:49.709691\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "32720", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"814418344814.33156\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/814418344814.33156\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"814418344814.33156\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"32720\"], \"delta\": \"0:00:00.107249\", \"end\": \"2023-10-09 16:48:45.006785\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:48:44.899536\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"495818061841.34008\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/495818061841.34008\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"495818061841.34008\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"2\", \"-t\", \"33503\"], \"delta\": \"0:00:00.122563\", \"end\": \"2023-10-09 16:48:49.832254\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 16:48:49.709691\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node2] => {"ansible_job_id": "363808806854.33367", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/363808806854.33367", "started": 1}
changed: [node1] => {"ansible_job_id": "679755060497.34219", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/679755060497.34219", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:41.173388", "end": "2023-10-09 16:50:39.197870", "rc": 0, "start": "2023-10-09 16:48:58.024482", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-2/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-2/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 12 
INFO:root:# Responses: 11 
INFO:root:Achieved QPS: 0.0916667 
INFO:root:Average Response Time(ms): 6.86609 
INFO:root:6.353 6.497 6.518 6.57 6.591 6.679 6.687 6.981 7.286 9.023 9.023 9.023 6.353 6.497 6.518 6.57 6.591 6.679 6.687 6.981 7.286 9.023 9.023 9.023 
INFO:root: Total response time 
INFO:root:6.353 6.497 6.518 6.57 6.591 6.679 6.687 6.981 7.286 9.023 9.023 9.023 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.594 0.598 0.602 0.603 0.605 0.608 0.61 0.624 0.632 0.633 0.633 0.633 
INFO:root: Unpack loadgen request time 0.055 0.056 0.056 0.057 0.057 0.057 0.058 0.061 0.061 0.065 0.065 0.065 
INFO:root: Get point ids time 
INFO:root:0.175 0.177 0.197 0.235 0.281 0.287 0.313 0.327 0.477 3.209 3.209 3.209 
INFO:root: Total time taken by index server: 
INFO:root:1.313 1.323 1.329 1.363 1.38 1.464 1.477 1.489 1.624 4.382 4.382 4.382 Average Index Time(ms): 1.67109 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.609 4.632 4.654 4.706 4.775 4.805 4.877 4.921 5.047 5.331 5.331 5.331 Average Bucket Time(ms): 4.78173 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.02 0.026 0.027 0.027 0.027 0.028 0.028 0.029 0.029 0.031 0.031 0.031 
INFO:root: Calculate knn time 
INFO:root:0.043 0.043 0.044 0.044 0.044 0.077 0.138 0.151 0.152 0.171 0.171 0.171 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.003 0.003 0.003 0.003 
INFO:root: Unpack bucket response time 0 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.047 0.048 0.049 0.05 0.05 0.052 0.053 0.053 0.054 0.07 0.07 0.07 
INFO:root: Pack index response time 0.047 0.048 0.049 0.05 0.05 0.052 0.053 0.053 0.054 0.07 0.07 0.07 
INFO:root: Unpack index response time 0.003 0.003 0.003 0.004 0.004 0.004 0.004 0.004 0.006 0.013 0.013 0.013 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-2/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-2/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

TASK [Leave Swarm] *************************************************************
changed: [node2] => {"ansible_job_id": "255114407800.33798", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/255114407800.33798", "started": 1}
changed: [node0] => {"ansible_job_id": "975528323487.1786", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/975528323487.1786", "started": 1}
changed: [node1] => {"ansible_job_id": "237758223145.34926", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/237758223145.34926", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Install HDSearch] ********************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

PLAY [Set Up Docker Curl] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node0]
ok: [node1]

PLAY [Make space to commit] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]
ok: [node2]
ok: [node1]

TASK [Make Space to Commit Image] **********************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node2] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.454873", "end": "2023-10-09 16:52:01.427726", "rc": 0, "start": "2023-10-09 16:51:56.972853", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node1] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.925127", "end": "2023-10-09 16:52:01.895864", "rc": 0, "start": "2023-10-09 16:51:56.970737", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node0] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:05.105446", "end": "2023-10-09 16:52:02.074477", "rc": 0, "start": "2023-10-09 16:51:56.969031", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}

PLAY [Install Profiler Dep] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Set profiler Hosts] ******************************************************
changed: [node2] => {"ansible_job_id": "25695698286.34535", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/25695698286.34535", "started": 1}
changed: [node1] => {"ansible_job_id": "689148285333.35749", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/689148285333.35749", "started": 1}

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node0]
ok: [node1]

TASK [Leave Swarm] *************************************************************
changed: [node2] => {"ansible_job_id": "775504876600.34667", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/775504876600.34667", "started": 1}
changed: [node0] => {"ansible_job_id": "28040133964.2778", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/28040133964.2778", "started": 1}
changed: [node1] => {"ansible_job_id": "430760716601.35910", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/430760716601.35910", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Init Master] *************************************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": "sudo docker swarm init --advertise-addr 10.10.1.1", "delta": "0:00:00.604769", "end": "2023-10-09 16:52:14.528379", "rc": 0, "start": "2023-10-09 16:52:13.923610", "stderr": "", "stderr_lines": [], "stdout": "Swarm initialized: current node (83ppjplnixwi2w43mhpuqpos5) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-3my89jhr9qrvawee97i9x8clq52vavdioaxdt4gsrkiwo8s03i-979qar3ob6w5737up4nf1mh6g 10.10.1.1:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.", "stdout_lines": ["Swarm initialized: current node (83ppjplnixwi2w43mhpuqpos5) is now a manager.", "", "To add a worker to this swarm, run the following command:", "", "    docker swarm join --token SWMTKN-1-3my89jhr9qrvawee97i9x8clq52vavdioaxdt4gsrkiwo8s03i-979qar3ob6w5737up4nf1mh6g 10.10.1.1:2377", "", "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions."]}

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Init Workers] ************************************************************
changed: [node1] => {"ansible_job_id": "605676227205.36068", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/605676227205.36068", "started": 1}
changed: [node2] => {"ansible_job_id": "731338965516.34802", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/731338965516.34802", "started": 1}

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Set uncore frequency] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Load msr kernel module] **************************************************
changed: [node2] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.008255", "end": "2023-10-09 16:52:22.426969", "rc": 0, "start": "2023-10-09 16:52:22.418714", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.008031", "end": "2023-10-09 16:52:22.446093", "rc": 0, "start": "2023-10-09 16:52:22.438062", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

TASK [Set uncore freq] *********************************************************
changed: [node2] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.006800", "end": "2023-10-09 16:52:22.734247", "rc": 0, "start": "2023-10-09 16:52:22.727447", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.006624", "end": "2023-10-09 16:52:22.754048", "rc": 0, "start": "2023-10-09 16:52:22.747424", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
node1                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 3", "delta": "0:15:26.245669", "end": "2023-10-09 17:08:13.827732", "rc": 0, "start": "2023-10-09 16:52:47.582063", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 3 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 3 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n35791\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"273175517514.36211\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/273175517514.36211\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"273175517514.36211\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"35791\"], \"delta\": \"0:00:00.123567\", \"end\": \"2023-10-09 17:08:06.682333\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:08:06.558766\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"171888584150.37494\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/171888584150.37494\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"171888584150.37494\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"37006\"], \"delta\": \"0:00:00.123200\", \"end\": \"2023-10-09 17:08:12.945668\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:08:12.822468\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "35791", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"273175517514.36211\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/273175517514.36211\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"273175517514.36211\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"35791\"], \"delta\": \"0:00:00.123567\", \"end\": \"2023-10-09 17:08:06.682333\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:08:06.558766\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"171888584150.37494\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/171888584150.37494\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"171888584150.37494\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"37006\"], \"delta\": \"0:00:00.123200\", \"end\": \"2023-10-09 17:08:12.945668\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:08:12.822468\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "723980419335.37698", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/723980419335.37698", "started": 1}
changed: [node2] => {"ansible_job_id": "696692202277.36415", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/696692202277.36415", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:40.723906", "end": "2023-10-09 17:10:01.946839", "rc": 0, "start": "2023-10-09 17:08:21.222933", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-3/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-3/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 1 
INFO:root:# Responses: 1 
INFO:root:Achieved QPS: 0.00833333 
INFO:root:Average Response Time(ms): 6.884 
INFO:root:6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 
INFO:root: Total response time 
INFO:root:6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 6.884 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 0.64 
INFO:root: Unpack loadgen request time 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 
INFO:root: Get point ids time 
INFO:root:0.315 0.315 0.315 0.315 0.315 0.315 0.315 0.315 0.315 0.315 0.315 0.315 
INFO:root: Total time taken by index server: 
INFO:root:1.606 1.606 1.606 1.606 1.606 1.606 1.606 1.606 1.606 1.606 1.606 1.606 Average Index Time(ms): 1.606 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.907 4.907 4.907 4.907 4.907 4.907 4.907 4.907 4.907 4.907 4.907 4.907 Average Bucket Time(ms): 4.907 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 
INFO:root: Calculate knn time 
INFO:root:0.044 0.044 0.044 0.044 0.044 0.044 0.044 0.044 0.044 0.044 0.044 0.044 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 
INFO:root: Pack index response time 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 0.069 
INFO:root: Unpack index response time 0.005 0.005 0.005 0.005 0.005 0.005 0.005 0.005 0.005 0.005 0.005 0.005 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-3/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-3/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 3", "delta": "0:01:32.027164", "end": "2023-10-09 17:12:59.509069", "rc": 0, "start": "2023-10-09 17:11:27.481905", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 3 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 3 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n36865\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"195673644868.37270\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/195673644868.37270\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"195673644868.37270\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"36865\"], \"delta\": \"0:00:00.121490\", \"end\": \"2023-10-09 17:12:53.776857\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:12:53.655367\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"23199225487.38630\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/23199225487.38630\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"23199225487.38630\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"38137\"], \"delta\": \"0:00:00.121121\", \"end\": \"2023-10-09 17:12:58.651509\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:12:58.530388\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "36865", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"195673644868.37270\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/195673644868.37270\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"195673644868.37270\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"36865\"], \"delta\": \"0:00:00.121490\", \"end\": \"2023-10-09 17:12:53.776857\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:12:53.655367\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"23199225487.38630\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/23199225487.38630\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"23199225487.38630\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"38137\"], \"delta\": \"0:00:00.121121\", \"end\": \"2023-10-09 17:12:58.651509\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:12:58.530388\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

ansible-playbook -v -i hosts -e "" --tags "setup_docker" ansible/install.yml
ansible-playbook -v -i hosts -e "" --tags "set_profiler_hosts" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_master" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_workers" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "MSR_VALUE=0x1414"  ansible/configure.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=0" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=0" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=0" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "setup_docker" ansible/install.yml
ansible-playbook -v -i hosts -e "" --tags "set_profiler_hosts" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_master" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_workers" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "MSR_VALUE=0x1414"  ansible/configure.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=1" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=1" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=1" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "setup_docker" ansible/install.yml
ansible-playbook -v -i hosts -e "" --tags "set_profiler_hosts" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_master" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_workers" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "MSR_VALUE=0x1414"  ansible/configure.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=2" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=2" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=2" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "setup_docker" ansible/install.yml
ansible-playbook -v -i hosts -e "" --tags "set_profiler_hosts" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_master" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_workers" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "MSR_VALUE=0x1414"  ansible/configure.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=3" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=3" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05" --tags "run_socwatch" ./ansible/profiler.ymlUsing /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Run remote socwatch] *****************************************************
changed: [node2] => {"ansible_job_id": "829744478052.37482", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/829744478052.37482", "started": 1}
changed: [node1] => {"ansible_job_id": "503693855185.38841", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/503693855185.38841", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:42.216355", "end": "2023-10-09 17:14:48.714644", "rc": 0, "start": "2023-10-09 17:13:06.498289", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-3/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-3/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.2] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 5 
INFO:root:# Responses: 5 
INFO:root:Achieved QPS: 0.0416667 
INFO:root:Average Response Time(ms): 6.368 
INFO:root:6.07 6.123 6.123 6.431 6.431 6.587 6.587 6.629 6.629 6.629 6.629 6.629 6.07 6.123 6.123 6.431 6.431 6.587 6.587 6.629 6.629 6.629 6.629 6.629 
INFO:root: Total response time 
INFO:root:6.07 6.123 6.123 6.431 6.431 6.587 6.587 6.629 6.629 6.629 6.629 6.629 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.611 0.622 0.622 0.632 0.632 0.634 0.634 0.644 0.644 0.644 0.644 0.644 
INFO:root: Unpack loadgen request time 0.056 0.057 0.057 0.057 0.057 0.057 0.057 0.061 0.061 0.061 0.061 0.061 
INFO:root: Get point ids time 
INFO:root:0.11 0.153 0.153 0.17 0.17 0.174 0.174 0.336 0.336 0.336 0.336 0.336 
INFO:root: Total time taken by index server: 
INFO:root:1.214 1.317 1.317 1.325 1.325 1.333 1.333 1.56 1.56 1.56 1.56 1.56 Average Index Time(ms): 1.3498 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.275 4.354 4.354 4.66 4.66 4.866 4.866 4.882 4.882 4.882 4.882 4.882 Average Bucket Time(ms): 4.6074 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.02 0.023 0.023 0.027 0.027 0.03 0.03 0.057 0.057 0.057 0.057 0.057 
INFO:root: Calculate knn time 
INFO:root:0.041 0.081 0.081 0.141 0.141 0.152 0.152 0.156 0.156 0.156 0.156 0.156 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.031 0.044 0.044 0.049 0.049 0.051 0.051 0.054 0.054 0.054 0.054 0.054 
INFO:root: Pack index response time 0.031 0.044 0.044 0.049 0.049 0.051 0.051 0.054 0.054 0.054 0.054 0.054 
INFO:root: Unpack index response time 0.008 0.008 0.008 0.008 0.008 0.008 0.008 0.013 0.013 0.013 0.013 0.013 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-3/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-3/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 3", "delta": "0:01:34.339930", "end": "2023-10-09 17:17:48.465220", "rc": 0, "start": "2023-10-09 17:16:14.125290", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 3 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 3 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n37914\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"956870426576.38331\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/956870426576.38331\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"956870426576.38331\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"37914\"], \"delta\": \"0:00:00.120449\", \"end\": \"2023-10-09 17:17:42.781552\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:17:42.661103\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"38304384569.39769\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/38304384569.39769\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"38304384569.39769\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"39279\"], \"delta\": \"0:00:00.123541\", \"end\": \"2023-10-09 17:17:47.619824\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:17:47.496283\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "37914", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"956870426576.38331\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/956870426576.38331\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"956870426576.38331\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"37914\"], \"delta\": \"0:00:00.120449\", \"end\": \"2023-10-09 17:17:42.781552\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:17:42.661103\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"38304384569.39769\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/38304384569.39769\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"38304384569.39769\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"3\", \"-t\", \"39279\"], \"delta\": \"0:00:00.123541\", \"end\": \"2023-10-09 17:17:47.619824\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:17:47.496283\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "698211210894.39972", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/698211210894.39972", "started": 1}
changed: [node2] => {"ansible_job_id": "265159045772.38535", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/265159045772.38535", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:41.069415", "end": "2023-10-09 17:19:37.512026", "rc": 0, "start": "2023-10-09 17:17:56.442611", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-3/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-3/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.2] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 12 
INFO:root:# Responses: 11 
INFO:root:Achieved QPS: 0.0916667 
INFO:root:Average Response Time(ms): 6.58273 
INFO:root:6.309 6.309 6.379 6.385 6.653 6.675 6.692 6.898 6.951 7.103 7.103 7.103 6.309 6.309 6.379 6.385 6.653 6.675 6.692 6.898 6.951 7.103 7.103 7.103 
INFO:root: Total response time 
INFO:root:6.309 6.309 6.379 6.385 6.653 6.675 6.692 6.898 6.951 7.103 7.103 7.103 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.574 0.581 0.584 0.6 0.6 0.6 0.601 0.605 0.606 0.619 0.619 0.619 
INFO:root: Unpack loadgen request time 0.054 0.054 0.056 0.056 0.056 0.06 0.06 0.061 0.064 0.066 0.066 0.066 
INFO:root: Get point ids time 
INFO:root:0.127 0.155 0.173 0.174 0.26 0.286 0.301 0.312 0.36 0.437 0.437 0.437 
INFO:root: Total time taken by index server: 
INFO:root:1.23 1.278 1.283 1.337 1.395 1.4 1.421 1.535 1.543 1.544 1.544 1.544 Average Index Time(ms): 1.38127 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.557 4.582 4.583 4.773 4.786 4.821 4.824 5.028 5.107 5.161 5.161 5.161 Average Bucket Time(ms): 4.78955 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.021 0.024 0.024 0.027 0.027 0.028 0.029 0.029 0.029 0.029 0.029 0.029 
INFO:root: Calculate knn time 
INFO:root:0.043 0.044 0.08 0.12 0.139 0.14 0.148 0.156 0.157 0.162 0.162 0.162 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.003 0.003 0.003 
INFO:root: Unpack bucket response time 0 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.048 0.05 0.05 0.05 0.05 0.05 0.051 0.051 0.052 0.081 0.081 0.081 
INFO:root: Pack index response time 0.048 0.05 0.05 0.05 0.05 0.05 0.051 0.051 0.052 0.081 0.081 0.081 
INFO:root: Unpack index response time 0.003 0.003 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-3/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-3/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]
ok: [node0]

TASK [Leave Swarm] *************************************************************
changed: [node0] => {"ansible_job_id": "680143285129.10007", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/680143285129.10007", "started": 1}
changed: [node1] => {"ansible_job_id": "95452763345.40399", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/95452763345.40399", "started": 1}
changed: [node2] => {"ansible_job_id": "505413065545.38953", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/505413065545.38953", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Install HDSearch] ********************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

PLAY [Set Up Docker Curl] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

PLAY [Make space to commit] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

TASK [Make Space to Commit Image] **********************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node1] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.402450", "end": "2023-10-09 17:20:57.094722", "rc": 0, "start": "2023-10-09 17:20:52.692272", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node2] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.430439", "end": "2023-10-09 17:20:57.136674", "rc": 0, "start": "2023-10-09 17:20:52.706235", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node0] => {"changed": true, "cmd": ["sudo", "~/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:05.107740", "end": "2023-10-09 17:20:57.805109", "rc": 0, "start": "2023-10-09 17:20:52.697369", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}

PLAY [Install Profiler Dep] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Set profiler Hosts] ******************************************************
changed: [node1] => {"ansible_job_id": "272716327930.508", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/272716327930.508", "started": 1}
changed: [node2] => {"ansible_job_id": "337913999397.39690", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/337913999397.39690", "started": 1}

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]
ok: [node1]
ok: [node2]

TASK [Leave Swarm] *************************************************************
changed: [node1] => {"ansible_job_id": "855674922164.673", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/855674922164.673", "started": 1}
changed: [node0] => {"ansible_job_id": "573780786220.10808", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/573780786220.10808", "started": 1}
changed: [node2] => {"ansible_job_id": "926809603481.39822", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/926809603481.39822", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Init Master] *************************************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": "sudo docker swarm init --advertise-addr 10.10.1.1", "delta": "0:00:00.600284", "end": "2023-10-09 17:21:07.337765", "rc": 0, "start": "2023-10-09 17:21:06.737481", "stderr": "", "stderr_lines": [], "stdout": "Swarm initialized: current node (ppv8cnvmv5wf4d0h9i4fg77lq) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-0n6snnve5ttevqvibsf0mea47peioockm7t9xb4y2m8biw4b8v-5tcvg51li4g9a9b4fr7rb6748 10.10.1.1:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.", "stdout_lines": ["Swarm initialized: current node (ppv8cnvmv5wf4d0h9i4fg77lq) is now a manager.", "", "To add a worker to this swarm, run the following command:", "", "    docker swarm join --token SWMTKN-1-0n6snnve5ttevqvibsf0mea47peioockm7t9xb4y2m8biw4b8v-5tcvg51li4g9a9b4fr7rb6748 10.10.1.1:2377", "", "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions."]}

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Init Workers] ************************************************************
changed: [node2] => {"ansible_job_id": "661445782015.39955", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/661445782015.39955", "started": 1}
changed: [node1] => {"ansible_job_id": "381057187710.824", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/381057187710.824", "started": 1}

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Set uncore frequency] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Load msr kernel module] **************************************************
changed: [node2] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.007972", "end": "2023-10-09 17:21:14.226774", "rc": 0, "start": "2023-10-09 17:21:14.218802", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.006704", "end": "2023-10-09 17:21:14.220929", "rc": 0, "start": "2023-10-09 17:21:14.214225", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

TASK [Set uncore freq] *********************************************************
changed: [node2] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.006754", "end": "2023-10-09 17:21:14.541092", "rc": 0, "start": "2023-10-09 17:21:14.534338", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.006753", "end": "2023-10-09 17:21:14.541381", "rc": 0, "start": "2023-10-09 17:21:14.534628", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
node1                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 4", "delta": "0:15:42.173396", "end": "2023-10-09 17:37:19.778053", "rc": 0, "start": "2023-10-09 17:21:37.604657", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 4 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 4 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n40802\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"951236510515.619\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/951236510515.619\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"951236510515.619\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"40802\"], \"delta\": \"0:00:00.123777\", \"end\": \"2023-10-09 17:37:13.559758\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:37:13.435981\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"483771792398.2194\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/483771792398.2194\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"483771792398.2194\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"1693\"], \"delta\": \"0:00:00.124745\", \"end\": \"2023-10-09 17:37:18.861449\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:37:18.736704\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "40802", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"951236510515.619\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/951236510515.619\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"951236510515.619\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"40802\"], \"delta\": \"0:00:00.123777\", \"end\": \"2023-10-09 17:37:13.559758\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:37:13.435981\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"483771792398.2194\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/483771792398.2194\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"483771792398.2194\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"1693\"], \"delta\": \"0:00:00.124745\", \"end\": \"2023-10-09 17:37:18.861449\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:37:18.736704\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node2] => {"ansible_job_id": "827148910222.858", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/827148910222.858", "started": 1}
changed: [node1] => {"ansible_job_id": "463892052429.2407", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/463892052429.2407", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:40.863691", "end": "2023-10-09 17:39:08.685998", "rc": 0, "start": "2023-10-09 17:37:27.822307", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-4/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-4/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 1 
INFO:root:# Responses: 1 
INFO:root:Achieved QPS: 0.00833333 
INFO:root:Average Response Time(ms): 6.56 
INFO:root:6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 
INFO:root: Total response time 
INFO:root:6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 6.56 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.641 0.641 0.641 0.641 0.641 0.641 0.641 0.641 0.641 0.641 0.641 0.641 
INFO:root: Unpack loadgen request time 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 
INFO:root: Get point ids time 
INFO:root:0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 
INFO:root: Total time taken by index server: 
INFO:root:1.628 1.628 1.628 1.628 1.628 1.628 1.628 1.628 1.628 1.628 1.628 1.628 Average Index Time(ms): 1.628 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.471 4.471 4.471 4.471 4.471 4.471 4.471 4.471 4.471 4.471 4.471 4.471 Average Bucket Time(ms): 4.471 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.024 0.024 0.024 0.024 0.024 0.024 0.024 0.024 0.024 0.024 0.024 0.024 
INFO:root: Calculate knn time 
INFO:root:0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 
INFO:root: Pack index response time 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 0.082 
INFO:root: Unpack index response time 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-4/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-4/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_client
Creating service microsuite_bucket
Creating service microsuite_midtier
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 4", "delta": "0:01:31.018573", "end": "2023-10-09 17:42:05.162331", "rc": 0, "start": "2023-10-09 17:40:34.143758", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 4 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 4 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n1329\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"685166883950.1743\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/685166883950.1743\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"685166883950.1743\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"1329\"], \"delta\": \"0:00:00.123951\", \"end\": \"2023-10-09 17:41:59.459442\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:41:59.335491\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"422538265418.3353\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/422538265418.3353\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"422538265418.3353\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"2866\"], \"delta\": \"0:00:00.121080\", \"end\": \"2023-10-09 17:42:04.320624\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:42:04.199544\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "1329", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"685166883950.1743\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/685166883950.1743\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"685166883950.1743\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"1329\"], \"delta\": \"0:00:00.123951\", \"end\": \"2023-10-09 17:41:59.459442\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:41:59.335491\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"422538265418.3353\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/422538265418.3353\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"422538265418.3353\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"2866\"], \"delta\": \"0:00:00.121080\", \"end\": \"2023-10-09 17:42:04.320624\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:42:04.199544\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "738433434266.3557", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/738433434266.3557", "started": 1}
changed: [node2] => {"ansible_job_id": "237562910347.1954", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/237562910347.1954", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:42.264708", "end": "2023-10-09 17:43:54.419821", "rc": 0, "start": "2023-10-09 17:42:12.155113", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-4/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-4/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.8] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 5 
INFO:root:# Responses: 5 
INFO:root:Achieved QPS: 0.0416667 
INFO:root:Average Response Time(ms): 6.993 
INFO:root:6.657 6.673 6.673 6.92 6.92 7.324 7.324 7.391 7.391 7.391 7.391 7.391 6.657 6.673 6.673 6.92 6.92 7.324 7.324 7.391 7.391 7.391 7.391 7.391 
INFO:root: Total response time 
INFO:root:6.657 6.673 6.673 6.92 6.92 7.324 7.324 7.391 7.391 7.391 7.391 7.391 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.61 0.613 0.613 0.614 0.614 0.614 0.614 0.652 0.652 0.652 0.652 0.652 
INFO:root: Unpack loadgen request time 0.059 0.06 0.06 0.062 0.062 0.063 0.063 0.094 0.094 0.094 0.094 0.094 
INFO:root: Get point ids time 
INFO:root:0.212 0.214 0.214 0.265 0.265 0.331 0.331 0.339 0.339 0.339 0.339 0.339 
INFO:root: Total time taken by index server: 
INFO:root:1.358 1.407 1.407 1.415 1.415 1.423 1.423 1.569 1.569 1.569 1.569 1.569 Average Index Time(ms): 1.4344 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.793 4.909 4.909 4.958 4.958 5.367 5.367 5.441 5.441 5.441 5.441 5.441 Average Bucket Time(ms): 5.0936 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.024 0.025 0.025 0.029 0.029 0.029 0.029 0.029 0.029 0.029 0.029 0.029 
INFO:root: Calculate knn time 
INFO:root:0.141 0.156 0.156 0.172 0.172 0.175 0.175 0.176 0.176 0.176 0.176 0.176 
INFO:root: Pack bucket response time 0.001 0.002 0.002 0.002 0.002 0.002 0.002 0.003 0.003 0.003 0.003 0.003 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.04 0.041 0.041 0.044 0.044 0.054 0.054 0.059 0.059 0.059 0.059 0.059 
INFO:root: Pack index response time 0.04 0.041 0.041 0.044 0.044 0.054 0.054 0.059 0.059 0.059 0.059 0.059 
INFO:root: Unpack index response time 0.004 0.004 0.004 0.005 0.005 0.005 0.005 0.005 0.005 0.005 0.005 0.005 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-4/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-4/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 4", "delta": "0:01:32.107568", "end": "2023-10-09 17:46:53.486330", "rc": 0, "start": "2023-10-09 17:45:21.378762", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 4 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd ~/hdsearch-multinode/profiler/; sudo ~/hdsearch-multinode/profiler/profiler.sh run_profiler 4 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n2389\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"460229703923.2808\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/460229703923.2808\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"460229703923.2808\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"2389\"], \"delta\": \"0:00:00.123138\", \"end\": \"2023-10-09 17:46:47.762392\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:46:47.639254\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"567330240588.4526\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/567330240588.4526\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"567330240588.4526\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"4033\"], \"delta\": \"0:00:00.123491\", \"end\": \"2023-10-09 17:46:52.610653\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:46:52.487162\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "2389", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"460229703923.2808\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/460229703923.2808\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"460229703923.2808\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"2389\"], \"delta\": \"0:00:00.123138\", \"end\": \"2023-10-09 17:46:47.762392\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:46:47.639254\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"567330240588.4526\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/567330240588.4526\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"567330240588.4526\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"4\", \"-t\", \"4033\"], \"delta\": \"0:00:00.123491\", \"end\": \"2023-10-09 17:46:52.610653\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-10-09 17:46:52.487162\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node2] => {"ansible_job_id": "47608519897.3019", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/47608519897.3019", "started": 1}
changed: [node1] => {"ansible_job_id": "878131281782.4730", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/878131281782.4730", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "~/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:42.194198", "end": "2023-10-09 17:48:42.686249", "rc": 0, "start": "2023-10-09 17:47:00.492051", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:python3 profiler/profiler.py -n node2 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-4/hdsearch/bucket_node2
INFO:root:python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-4/hdsearch/midtier_node1
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:304:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:306:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.3.5] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 12 
INFO:root:# Responses: 11 
INFO:root:Achieved QPS: 0.0916667 
INFO:root:Average Response Time(ms): 6.59727 
INFO:root:6.178 6.442 6.466 6.559 6.639 6.656 6.853 6.944 6.973 6.995 6.995 6.995 6.178 6.442 6.466 6.559 6.639 6.656 6.853 6.944 6.973 6.995 6.995 6.995 
INFO:root: Total response time 
INFO:root:6.178 6.442 6.466 6.559 6.639 6.656 6.853 6.944 6.973 6.995 6.995 6.995 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.593 0.595 0.596 0.601 0.606 0.609 0.613 0.618 0.62 0.659 0.659 0.659 
INFO:root: Unpack loadgen request time 0.055 0.056 0.056 0.057 0.058 0.06 0.061 0.062 0.063 0.063 0.063 0.063 
INFO:root: Get point ids time 
INFO:root:0.18 0.187 0.202 0.239 0.284 0.291 0.312 0.327 0.407 0.442 0.442 0.442 
INFO:root: Total time taken by index server: 
INFO:root:1.299 1.313 1.336 1.362 1.391 1.413 1.52 1.521 1.526 1.569 1.569 1.569 Average Index Time(ms): 1.41345 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.55 4.589 4.695 4.785 4.787 4.833 5.135 5.154 5.16 5.246 5.246 5.246 Average Bucket Time(ms): 4.81591 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.023 0.027 0.027 0.028 0.028 0.028 0.029 0.029 0.029 0.035 0.035 0.035 
INFO:root: Calculate knn time 
INFO:root:0.044 0.045 0.061 0.122 0.142 0.142 0.161 0.175 0.176 0.178 0.178 0.178 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.033 0.049 0.049 0.05 0.05 0.051 0.052 0.052 0.053 0.08 0.08 0.08 
INFO:root: Pack index response time 0.033 0.049 0.049 0.05 0.05 0.051 0.052 0.052 0.053 0.08 0.08 0.08 
INFO:root: Unpack index response time 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.005 0.005 0.005 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-4/hdsearch_client
INFO:root:sudo chmod 777 /users/cseas002/data/TEST/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1-4/hdsearch_client
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node0]
ok: [node1]

TASK [Leave Swarm] *************************************************************
changed: [node2] => {"ansible_job_id": "800949995949.3414", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/800949995949.3414", "started": 1}
changed: [node1] => {"ansible_job_id": "917061258415.5174", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/917061258415.5174", "started": 1}
changed: [node0] => {"ansible_job_id": "328291852486.17060", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/328291852486.17060", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=3" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "setup_docker" ansible/install.yml
ansible-playbook -v -i hosts -e "" --tags "set_profiler_hosts" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_master" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "init_workers" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "MSR_VALUE=0x1414"  ansible/configure.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=4" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=4" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "HOST_FILE=/users/cseas002/HDSearch-Multinode/hosts ITERATION=4" --tags "run_profiler" ansible/profiler.yml
Profilerrrrr putput 0
ansible-playbook -v -i hosts -e "MONITOR_TIME=40 OUTPUT_FILE=turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.1" --tags "run_socwatch" ./ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "check_status" ansible/hdsearch.yml
ansible-playbook -v -i hosts -e "" --tags "kill_profiler" ansible/profiler.yml
ansible-playbook -v -i hosts -e "" --tags "leave_swarm" ansible/hdsearch.yml
