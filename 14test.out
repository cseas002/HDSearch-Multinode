Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Install HDSearch] ********************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

PLAY [Set Up Docker Curl] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

PLAY [Make space to commit] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node0]
ok: [node2]

TASK [Make Space to Commit Image] **********************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": ["sudo", "/users/cseas002/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:00.879091", "end": "2023-10-11 17:07:29.603748", "rc": 0, "start": "2023-10-11 17:07:28.724657", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\n\"docker rmi\" requires at least 1 argument.\nSee 'docker rmi --help'.\n\nUsage:  docker rmi [OPTIONS] IMAGE [IMAGE...]\n\nRemove one or more images\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "\"docker rmi\" requires at least 1 argument.", "See 'docker rmi --help'.", "", "Usage:  docker rmi [OPTIONS] IMAGE [IMAGE...]", "", "Remove one or more images", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": ["sudo", "/users/cseas002/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:00.954996", "end": "2023-10-11 17:07:29.688511", "rc": 0, "start": "2023-10-11 17:07:28.733515", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\n\"docker rmi\" requires at least 1 argument.\nSee 'docker rmi --help'.\n\nUsage:  docker rmi [OPTIONS] IMAGE [IMAGE...]\n\nRemove one or more images\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "\"docker rmi\" requires at least 1 argument.", "See 'docker rmi --help'.", "", "Usage:  docker rmi [OPTIONS] IMAGE [IMAGE...]", "", "Remove one or more images", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "", "stdout_lines": []}
changed: [node2] => {"changed": true, "cmd": ["sudo", "/users/cseas002/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:00.981950", "end": "2023-10-11 17:07:29.713018", "rc": 0, "start": "2023-10-11 17:07:28.731068", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\n\"docker rmi\" requires at least 1 argument.\nSee 'docker rmi --help'.\n\nUsage:  docker rmi [OPTIONS] IMAGE [IMAGE...]\n\nRemove one or more images\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "\"docker rmi\" requires at least 1 argument.", "See 'docker rmi --help'.", "", "Usage:  docker rmi [OPTIONS] IMAGE [IMAGE...]", "", "Remove one or more images", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "", "stdout_lines": []}

PLAY [Install Profiler Dep] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

TASK [Leave Swarm] *************************************************************
changed: [node0] => {"ansible_job_id": "328687182021.12790", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/328687182021.12790", "started": 1}
changed: [node2] => {"ansible_job_id": "553569630405.8001", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/553569630405.8001", "started": 1}
changed: [node1] => {"ansible_job_id": "351691223740.8076", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/351691223740.8076", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Init Master] *************************************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": "sudo docker swarm init --advertise-addr 10.10.1.1", "delta": "0:00:00.614659", "end": "2023-10-11 17:07:36.889135", "rc": 0, "start": "2023-10-11 17:07:36.274476", "stderr": "", "stderr_lines": [], "stdout": "Swarm initialized: current node (q84bsbu2s9jhzw6d422r540e5) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-3lq9feyupqaphus099vbiujll8d07lqqz91baalbwlzitzqdib-9tee3526abquwyafz5c1pnne5 10.10.1.1:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.", "stdout_lines": ["Swarm initialized: current node (q84bsbu2s9jhzw6d422r540e5) is now a manager.", "", "To add a worker to this swarm, run the following command:", "", "    docker swarm join --token SWMTKN-1-3lq9feyupqaphus099vbiujll8d07lqqz91baalbwlzitzqdib-9tee3526abquwyafz5c1pnne5 10.10.1.1:2377", "", "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions."]}

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Init Workers] ************************************************************
changed: [node2] => {"ansible_job_id": "528567798327.8130", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/528567798327.8130", "started": 1}
changed: [node1] => {"ansible_job_id": "829111323890.8205", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/829111323890.8205", "started": 1}

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Set uncore frequency] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Load msr kernel module] **************************************************
changed: [node2] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.007977", "end": "2023-10-11 17:07:45.653563", "rc": 0, "start": "2023-10-11 17:07:45.645586", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.008025", "end": "2023-10-11 17:07:45.659887", "rc": 0, "start": "2023-10-11 17:07:45.651862", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

TASK [Set uncore freq] *********************************************************
changed: [node2] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.007191", "end": "2023-10-11 17:07:45.960833", "rc": 0, "start": "2023-10-11 17:07:45.953642", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.007271", "end": "2023-10-11 17:07:45.989955", "rc": 0, "start": "2023-10-11 17:07:45.982684", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
node1                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node2] => {"ansible_job_id": "862951424692.8674", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/862951424692.8674", "started": 1}
changed: [node1] => {"ansible_job_id": "58261778658.8736", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/58261778658.8736", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "/users/cseas002/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:17:15.181136", "end": "2023-10-11 17:25:28.568532", "rc": 0, "start": "2023-10-11 17:08:13.387396", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:305:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:307:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:Next time = 1697063108132478.250000
INFO:root:Curr time = 1697063108132479.000000
INFO:root:Next time = 1697063208132481.250000
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 1 
INFO:root:# Responses: 1 
INFO:root:Achieved QPS: 0.00833333 
INFO:root:Average Response Time(ms): 6.232 
INFO:root:6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 
INFO:root: Total response time 
INFO:root:6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 6.232 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.655 0.655 0.655 0.655 0.655 0.655 0.655 0.655 0.655 0.655 0.655 0.655 
INFO:root: Unpack loadgen request time 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 
INFO:root: Get point ids time 
INFO:root:0.326 0.326 0.326 0.326 0.326 0.326 0.326 0.326 0.326 0.326 0.326 0.326 
INFO:root: Total time taken by index server: 
INFO:root:1.59 1.59 1.59 1.59 1.59 1.59 1.59 1.59 1.59 1.59 1.59 1.59 Average Index Time(ms): 1.59 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.316 4.316 4.316 4.316 4.316 4.316 4.316 4.316 4.316 4.316 4.316 4.316 Average Bucket Time(ms): 4.316 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.023 0.023 0.023 0.023 0.023 0.023 0.023 0.023 0.023 0.023 0.023 0.023 
INFO:root: Calculate knn time 
INFO:root:0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 0.043 
INFO:root: Pack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Unpack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Merge time 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 
INFO:root: Pack index response time 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 0.061 
INFO:root: Unpack index response time 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-0/hdsearch_client
INFO:root:touch: cannot touch '/users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-0/hdsearch_client': No such file or directory
INFO:root:sudo chmod 777 /users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-0/hdsearch_client
INFO:root:chmod: cannot access '/users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-0/hdsearch_client': No such file or directory
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node2] => {"ansible_job_id": "140604626561.10062", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/140604626561.10062", "started": 1}
changed: [node1] => {"ansible_job_id": "135127068904.10298", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/135127068904.10298", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "/users/cseas002/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:03:20.892822", "end": "2023-10-11 17:30:24.417631", "rc": 0, "start": "2023-10-11 17:27:03.524809", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:305:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:307:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.2.5] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:Next time = 1697063324024527.750000
INFO:root:Curr time = 1697063324024528.000000
INFO:root:Next time = 1697063344024527.750000
INFO:root:1 1 1 Curr time = 1697063344024528.000000
INFO:root:Next time = 1697063364024527.750000
INFO:root:Curr time = 1697063364024528.000000
INFO:root:Next time = 1697063384024527.750000
INFO:root:Curr time = 1697063384024528.000000
INFO:root:Next time = 1697063404024527.750000
INFO:root:Curr time = 1697063404024528.000000
INFO:root:Next time = 1697063424024527.750000
INFO:root:End of Actual Run
INFO:root:# Requests: 5 
INFO:root:# Responses: 5 
INFO:root:Achieved QPS: 0.0416667 
INFO:root:Average Response Time(ms): 6.146 
INFO:root:5.927 5.994 5.994 6.006 6.006 6.158 6.158 6.645 6.645 6.645 6.645 6.645 5.927 5.994 5.994 6.006 6.006 6.158 6.158 6.645 6.645 6.645 6.645 6.645 
INFO:root: Total response time 
INFO:root:5.927 5.994 5.994 6.006 6.006 6.158 6.158 6.645 6.645 6.645 6.645 6.645 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.647 0.649 0.649 0.655 0.655 0.656 0.656 0.674 0.674 0.674 0.674 0.674 
INFO:root: Unpack loadgen request time 0.058 0.059 0.059 0.06 0.06 0.06 0.06 0.064 0.064 0.064 0.064 0.064 
INFO:root: Get point ids time 
INFO:root:0.179 0.18 0.18 0.243 0.243 0.315 0.315 0.358 0.358 0.358 0.358 0.358 
INFO:root: Total time taken by index server: 
INFO:root:1.451 1.539 1.539 1.552 1.552 1.586 1.586 1.725 1.725 1.725 1.725 1.725 Average Index Time(ms): 1.5706 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:3.957 4.011 4.011 4.14 4.14 4.234 4.234 4.71 4.71 4.71 4.71 4.71 Average Bucket Time(ms): 4.2104 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.009 0.01 0.01 0.025 0.025 0.026 0.026 0.027 0.027 0.027 0.027 0.027 
INFO:root: Calculate knn time 
INFO:root:0.043 0.045 0.045 0.096 0.096 0.11 0.11 0.178 0.178 0.178 0.178 0.178 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.002 0.002 0.002 0.002 0.002 
INFO:root: Merge time 0.034 0.035 0.035 0.043 0.043 0.049 0.049 0.062 0.062 0.062 0.062 0.062 
INFO:root: Pack index response time 0.034 0.035 0.035 0.043 0.043 0.049 0.049 0.062 0.062 0.062 0.062 0.062 
INFO:root: Unpack index response time 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 0.004 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-0/hdsearch_client
INFO:root:touch: cannot touch '/users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-0/hdsearch_client': No such file or directory
INFO:root:sudo chmod 777 /users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-0/hdsearch_client
INFO:root:chmod: cannot access '/users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.05-0/hdsearch_client': No such file or directory
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]
ok: [node1]
ok: [node2]

TASK [Leave Swarm] *************************************************************
changed: [node0] => {"ansible_job_id": "201243496751.31879", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/201243496751.31879", "started": 1}
changed: [node2] => {"ansible_job_id": "32908564034.10575", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/32908564034.10575", "started": 1}
changed: [node1] => {"ansible_job_id": "348997508396.10888", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/348997508396.10888", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Install HDSearch] ********************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

PLAY [Set Up Docker Curl] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

PLAY [Make space to commit] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]
ok: [node1]
ok: [node2]

TASK [Make Space to Commit Image] **********************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node2] => {"changed": true, "cmd": ["sudo", "/users/cseas002/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.448143", "end": "2023-10-11 17:31:41.125524", "rc": 0, "start": "2023-10-11 17:31:36.677381", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node1] => {"changed": true, "cmd": ["sudo", "/users/cseas002/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:04.461305", "end": "2023-10-11 17:31:41.140299", "rc": 0, "start": "2023-10-11 17:31:36.678994", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node0] => {"changed": true, "cmd": ["sudo", "/users/cseas002/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:05.443599", "end": "2023-10-11 17:31:42.122665", "rc": 0, "start": "2023-10-11 17:31:36.679066", "stderr": "\"docker rm\" requires at least 1 argument.\nSee 'docker rm --help'.\n\nUsage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory '/dev/mkdocker': File exists", "stderr_lines": ["\"docker rm\" requires at least 1 argument.", "See 'docker rm --help'.", "", "Usage:  docker rm [OPTIONS] CONTAINER [CONTAINER...]", "", "Remove one or more containers", "Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory '/dev/mkdocker': File exists"], "stdout": "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}

PLAY [Install Profiler Dep] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node0]
ok: [node1]

TASK [Leave Swarm] *************************************************************
changed: [node0] => {"ansible_job_id": "832081274198.32636", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/832081274198.32636", "started": 1}
changed: [node2] => {"ansible_job_id": "865504858918.11302", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/865504858918.11302", "started": 1}
changed: [node1] => {"ansible_job_id": "303307361113.11627", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/303307361113.11627", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Init Master] *************************************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": "sudo docker swarm init --advertise-addr 10.10.1.1", "delta": "0:00:00.600536", "end": "2023-10-11 17:31:48.312684", "rc": 0, "start": "2023-10-11 17:31:47.712148", "stderr": "", "stderr_lines": [], "stdout": "Swarm initialized: current node (ng96t2j1gcl7r59dac4flkcju) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-0rznwlaptz7fzsapws21s9y7k5d5ar7b1egi7pnhhn3brzav26-7u1nqjvftm4rrzulv7yica1jr 10.10.1.1:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.", "stdout_lines": ["Swarm initialized: current node (ng96t2j1gcl7r59dac4flkcju) is now a manager.", "", "To add a worker to this swarm, run the following command:", "", "    docker swarm join --token SWMTKN-1-0rznwlaptz7fzsapws21s9y7k5d5ar7b1egi7pnhhn3brzav26-7u1nqjvftm4rrzulv7yica1jr 10.10.1.1:2377", "", "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions."]}

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Init Workers] ************************************************************
changed: [node2] => {"ansible_job_id": "36663173731.11434", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/36663173731.11434", "started": 1}
changed: [node1] => {"ansible_job_id": "535759742965.11760", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/535759742965.11760", "started": 1}

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Set uncore frequency] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Load msr kernel module] **************************************************
changed: [node2] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.008141", "end": "2023-10-11 17:31:54.123393", "rc": 0, "start": "2023-10-11 17:31:54.115252", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.007879", "end": "2023-10-11 17:31:54.140728", "rc": 0, "start": "2023-10-11 17:31:54.132849", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

TASK [Set uncore freq] *********************************************************
changed: [node2] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.007001", "end": "2023-10-11 17:31:54.411810", "rc": 0, "start": "2023-10-11 17:31:54.404809", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.006647", "end": "2023-10-11 17:31:54.441780", "rc": 0, "start": "2023-10-11 17:31:54.435133", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
node1                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
changed: [node1] => {"ansible_job_id": "344034437189.12246", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/344034437189.12246", "started": 1}
changed: [node2] => {"ansible_job_id": "443357513778.11912", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/443357513778.11912", "started": 1}

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "/users/cseas002/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:17:10.623222", "end": "2023-10-11 17:49:34.350892", "rc": 0, "start": "2023-10-11 17:32:23.727670", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node2
INFO:root:2
INFO:root:sudo docker service logs microsuite_client --raw
INFO:root:client start
INFO:root:mv: cannot stat 'image_feature_vectors.dat': No such file or directory
INFO:root:rm -f *.o *.pb.cc *.pb.h load_generator_open_loop load_generator_closed_loop kill_index_server_empty
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o helper_files/mid_tier_client_helper.o helper_files/mid_tier_client_helper.cc
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid CreateDatasetFromBinaryFile(const string&, MultiplePoints*)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:296:77:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if([01;35m[Kfread(values, sizeof(float), dataset_dimensions, dataset_binary) == dataset_dimensions[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:[m[K In function '[01m[Kvoid ResetMetaStats(GlobalStats*, int)[m[K':
INFO:root:[01m[Khelper_files/mid_tier_client_helper.cc:586:31:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     for(unsigned int i = 0; [01;35m[Ki < number_of_bucket_servers[m[K; i++)
INFO:root:                             [01;35m[K~~^~~~~~~~~~~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_open_loop.o load_generator_open_loop.cc
INFO:root:[01m[Kload_generator_open_loop.cc:[m[K In function '[01m[Kint main(int, char**)[m[K':
INFO:root:[01m[Kload_generator_open_loop.cc:305:51:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:     while ([01;35m[Kresponses_recvd->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:            [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:[01m[Kload_generator_open_loop.cc:307:75:[m[K [01;35m[Kwarning: [m[Kcomparison between signed and unsigned integer expressions [[01;35m[K-Wsign-compare[m[K]
INFO:root:         if (curr_time >= next_time && [01;35m[Knum_requests->AtomicallyReadCount() < overall_queries[m[K)
INFO:root:                                       [01;35m[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~[m[K
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_open_loop.o -O3 -o load_generator_open_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o load_generator_closed_loop.o load_generator_closed_loop.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o load_generator_closed_loop.o -O3 -o load_generator_closed_loop -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:g++ -std=c++11 -O3 -mavx2 -mavx -fopenmp  -DMKL_ILP64 -m64 -I/opt/intel/mkl/include -I../ -I/usr/local/include -pthread -O3 -I../ -g -Wall -fopenmp -I../  -c -o kill_index_server_empty.o kill_index_server_empty.cc
INFO:root:g++ ../protoc_files/mid_tier.pb.o ../protoc_files/mid_tier.grpc.pb.o ../bucket_service/src/multiple_points.o ../bucket_service/src/point.o ../bucket_service/src/utils.o ../bucket_service/src/dist_calc.o ../bucket_service/src/custom_priority_queue.o helper_files/mid_tier_client_helper.o helper_files/timing.o helper_files/utils.o kill_index_server_empty.o -O3 -o kill_index_server_empty -L/usr/local/lib `pkg-config --libs grpc++ grpc` -lprotobuf -lpthread -I /usr/local/include -lflann -fopenmp -L/usr/lib64 -lstdc++ -lssl -lcrypto -fopenmp -Wl,--start-group /opt/intel/mkl/lib/intel64/libmkl_intel_ilp64.a /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.a /opt/intel/mkl/lib/intel64/libmkl_core.a -Wl,--end-group -lgomp -lpthread -lm -ldl -I../
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:midtier [10.0.1.5] 50054 (?) : Connection refused
INFO:root:         @    @       ï¿½           ?                midtier launched
INFO:root:profilers launched
INFO:root:mkdir: cannot create directory './results': File exists
INFO:root:1 1 1 # Requests: 0 
INFO:root:# Responses: 0 
INFO:root:!!!!!!!End of Warmup Period!!!!!!! 
INFO:root:Next time = 1697064553524440.250000
INFO:root:Curr time = 1697064553524441.000000
INFO:root:Next time = 1697064653524443.250000
INFO:root:1 1 1 End of Actual Run
INFO:root:# Requests: 1 
INFO:root:# Responses: 1 
INFO:root:Achieved QPS: 0.00833333 
INFO:root:Average Response Time(ms): 6.229 
INFO:root:6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 
INFO:root: Total response time 
INFO:root:6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 6.229 
INFO:root:
INFO:root: Index creation time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Update index util time 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 
INFO:root: Unpack loadgen request time 0.057 0.057 0.057 0.057 0.057 0.057 0.057 0.057 0.057 0.057 0.057 0.057 
INFO:root: Get point ids time 
INFO:root:0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 0.329 
INFO:root: Total time taken by index server: 
INFO:root:1.612 1.612 1.612 1.612 1.612 1.612 1.612 1.612 1.612 1.612 1.612 1.612 Average Index Time(ms): 1.612 
INFO:root:
INFO:root: Get bucket responses time 
INFO:root:4.248 4.248 4.248 4.248 4.248 4.248 4.248 4.248 4.248 4.248 4.248 4.248 Average Bucket Time(ms): 4.248 
INFO:root:
INFO:root: Create bucket request time 0 0 0 0 0 0 0 0 0 0 0 0 
INFO:root: Unpack bucket request time 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 0.025 
INFO:root: Calculate knn time 
INFO:root:0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 0.045 
INFO:root: Pack bucket response time 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 
INFO:root: Unpack bucket response time 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 
INFO:root: Merge time 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 
INFO:root: Pack index response time 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 
INFO:root: Unpack index response time 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 
INFO:root: 0
INFO:root:got kill ack
INFO:root:[libprotobuf FATAL /usr/local/include/google/protobuf/repeated_field.h:1535] CHECK failed: (index) < (current_size_): 
INFO:root:terminate called after throwing an instance of 'google::protobuf::FatalException'
INFO:root:  what():  CHECK failed: (index) < (current_size_): 
INFO:root:sudo touch /users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-1/hdsearch_client
INFO:root:touch: cannot touch '/users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-1/hdsearch_client': No such file or directory
INFO:root:sudo chmod 777 /users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-1/hdsearch_client
INFO:root:chmod: cannot access '/users/cseas002/data/TEST14/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=0.01-1/hdsearch_client': No such file or directory
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
fatal: [node2]: FAILED! => {"msg": "failure writing module data to temporary file for transfer: [Errno 28] No space left on device"}
fatal: [node1]: FAILED! => {"msg": "failure writing module data to temporary file for transfer: [Errno 28] No space left on device"}

PLAY RECAP *********************************************************************
node1                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
fatal: [node0]: FAILED! => {"ansible_facts": {}, "changed": false, "failed_modules": {"setup": {"ansible_facts": {"discovered_interpreter_python": "/usr/bin/python"}, "deprecations": [{"msg": "Distribution Ubuntu 18.04 on host node0 should use /usr/bin/python3, but is using /usr/bin/python for backward compatibility with prior Ansible releases. A future Ansible release will default to using the discovered platform python for this host. See https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information", "version": "2.12"}], "exception": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "failed": true, "module_stderr": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "module_stdout": "", "msg": "MODULE FAILURE\nSee stdout/stderr for the exact error", "rc": 1}}, "msg": "The following modules failed to execute: setup\n"}

PLAY RECAP *********************************************************************
node0                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Run remote socwatch] *****************************************************
fatal: [node2]: FAILED! => {"msg": "failure writing module data to temporary file for transfer: [Errno 28] No space left on device"}
fatal: [node1]: FAILED! => {"msg": "failure writing module data to temporary file for transfer: [Errno 28] No space left on device"}

PLAY RECAP *********************************************************************
node1                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
fatal: [node0]: FAILED! => {"ansible_facts": {}, "changed": false, "failed_modules": {"setup": {"ansible_facts": {"discovered_interpreter_python": "/usr/bin/python"}, "deprecations": [{"msg": "Distribution Ubuntu 18.04 on host node0 should use /usr/bin/python3, but is using /usr/bin/python for backward compatibility with prior Ansible releases. A future Ansible release will default to using the discovered platform python for this host. See https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information", "version": "2.12"}], "exception": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "failed": true, "module_stderr": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "module_stdout": "", "msg": "MODULE FAILURE\nSee stdout/stderr for the exact error", "rc": 1}}, "msg": "The following modules failed to execute: setup\n"}

PLAY RECAP *********************************************************************
node0                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
fatal: [node0]: FAILED! => {"ansible_facts": {}, "changed": false, "failed_modules": {"setup": {"ansible_facts": {"discovered_interpreter_python": "/usr/bin/python"}, "deprecations": [{"msg": "Distribution Ubuntu 18.04 on host node0 should use /usr/bin/python3, but is using /usr/bin/python for backward compatibility with prior Ansible releases. A future Ansible release will default to using the discovered platform python for this host. See https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information", "version": "2.12"}], "exception": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "failed": true, "module_stderr": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "module_stdout": "", "msg": "MODULE FAILURE\nSee stdout/stderr for the exact error", "rc": 1}}, "msg": "The following modules failed to execute: setup\n"}

PLAY RECAP *********************************************************************
node0                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
fatal: [node0]: FAILED! => {"ansible_facts": {}, "changed": false, "failed_modules": {"setup": {"ansible_facts": {"discovered_interpreter_python": "/usr/bin/python"}, "deprecations": [{"msg": "Distribution Ubuntu 18.04 on host node0 should use /usr/bin/python3, but is using /usr/bin/python for backward compatibility with prior Ansible releases. A future Ansible release will default to using the discovered platform python for this host. See https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information", "version": "2.12"}], "exception": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "failed": true, "module_stderr": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "module_stdout": "", "msg": "MODULE FAILURE\nSee stdout/stderr for the exact error", "rc": 1}}, "msg": "The following modules failed to execute: setup\n"}

PLAY RECAP *********************************************************************
node0                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
fatal: [node0]: FAILED! => {"ansible_facts": {}, "changed": false, "failed_modules": {"setup": {"ansible_facts": {"discovered_interpreter_python": "/usr/bin/python"}, "deprecations": [{"msg": "Distribution Ubuntu 18.04 on host node0 should use /usr/bin/python3, but is using /usr/bin/python for backward compatibility with prior Ansible releases. A future Ansible release will default to using the discovered platform python for this host. See https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information", "version": "2.12"}], "exception": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "failed": true, "module_stderr": "Traceback (most recent call last):\n  File \"<stdin>\", line 102, in <module>\n  File \"<stdin>\", line 90, in _ansiballz_main\nIOError: [Errno 28] No space left on device\n", "module_stdout": "", "msg": "MODULE FAILURE\nSee stdout/stderr for the exact error", "rc": 1}}, "msg": "The following modules failed to execute: setup\n"}

PLAY RECAP *********************************************************************
node0                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node0]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node0                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    resRemoving service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node0]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *************************************************Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node0]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *************************************************Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node0]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *************************************************Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node0]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *************************************************Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_client
Creating service microsuite_bucket
Creating service microsuite_midtier
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node0]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *************************************************Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node0]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *************************************************Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node0]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *************************************************Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node0]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *************************************************Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************

INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node2]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: IOError: [Errno 28] No space left on device
fatal: [node1]: FAILED! => {"msg": "Unexpected failure during module execution.", "stdout": ""}

PLAY RECAP *********************************************************************
node1                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Unhandled error:
 Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/ansible/config/manager.py", line 575, in update_config_data
    value, origin = self.get_config_value_and_origin(config, configfile)
  File "/usr/lib/python2.7/dist-packages/ansible/config/manager.py", line 519, in get_config_value_and_origin
    value = ensure_type(value, defs[config].get('type'), origin=origin)
  File "/usr/lib/python2.7/dist-packages/ansible/config/manager.py", line 124, in ensure_type
    value = tempfile.mkdtemp(prefix=prefix, dir=value)
  File "/usr/lib/python2.7/tempfile.py", line 339, in mkdtemp
    _os.mkdir(file, 0700)
OSError: [Errno 28] No space left on device: '/u