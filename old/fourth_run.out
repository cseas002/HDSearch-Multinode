Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Install HDSearch] ********************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

PLAY [Set Up Docker Curl] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

PLAY [Make space to commit] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

TASK [Make Space to Commit Image] **********************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": ["sudo", "/users/cseas002/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:07.288611", "end": "2023-09-18 14:08:44.438044", "rc": 0, "start": "2023-09-18 14:08:37.149433", "stderr": "Warning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory ‘/dev/mkdocker’: File exists", "stderr_lines": ["Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory ‘/dev/mkdocker’: File exists"], "stdout": "98f6a7f5924c\nUntagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["98f6a7f5924c", "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node2] => {"changed": true, "cmd": ["sudo", "/users/cseas002/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:07.761855", "end": "2023-09-18 14:08:44.918982", "rc": 0, "start": "2023-09-18 14:08:37.157127", "stderr": "Warning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory ‘/dev/mkdocker’: File exists", "stderr_lines": ["Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory ‘/dev/mkdocker’: File exists"], "stdout": "70b574052b5a\nUntagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["70b574052b5a", "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}
changed: [node1] => {"changed": true, "cmd": ["sudo", "/users/cseas002/HDSearch-Multinode/scripts/change-storage-location-docker.sh"], "delta": "0:00:07.761784", "end": "2023-09-18 14:08:44.919825", "rc": 0, "start": "2023-09-18 14:08:37.158041", "stderr": "Warning: Stopping docker.service, but it can still be activated by:\n  docker.socket\nmkdir: cannot create directory ‘/dev/mkdocker’: File exists", "stderr_lines": ["Warning: Stopping docker.service, but it can still be activated by:", "  docker.socket", "mkdir: cannot create directory ‘/dev/mkdocker’: File exists"], "stdout": "f91b4de61837\nUntagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c\nDeleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15\nDeleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750\nDeleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314\nDeleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144\nDeleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1\nDeleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1\nDeleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098\nDeleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4\nDeleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d\nDeleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55\nDeleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8\nDeleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230\nDeleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59\nDeleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918", "stdout_lines": ["f91b4de61837", "Untagged: mklean/baseline-microsuite@sha256:d01aee25d7aebe6624aa5b1acccf75d5554700f866a7fdc57676aec74a86c44c", "Deleted: sha256:90f8ba6af25a3e89eccd56ed7453e1c91120b13f25c92f72956548f552acdb15", "Deleted: sha256:7d7bb52e2e991a9ef12f46b9ca755d11ab136da63216c3d7b3ae7e5db1ac8750", "Deleted: sha256:a8a53f5f6c8630b73641635133a526fc81a347a1b736bd558e97463a7d290314", "Deleted: sha256:9bf3932968c1bb680c8217ba99ee2d0179f5e308673f184da4e36e3c20709144", "Deleted: sha256:750af7b8c4edd1bde0d80babfc97b10ff9be844dade2e16524654329c3e3acf1", "Deleted: sha256:aa99de0dee7cececefd190f4be8b847d4b14198bcdeb72f7b5a1fb7d828b58a1", "Deleted: sha256:822e0342cb2ed6b3ede926b31766466892d8c3c014017d8223f42b1eb8730098", "Deleted: sha256:9bd80ab5dfc88af200c32bb0a6987831e3daa06505699cd4793eaa318c48b0c4", "Deleted: sha256:f00fab48208aa68c0baf2ab85900f7e82bdd99b2cd823dcc80d698fe3a3fa80d", "Deleted: sha256:16f559e8ec664cf176d3f2533a13bf78862e73e6e0e4ee076545495335c74b55", "Deleted: sha256:252cd7005ec1a73c4bca3c05f0a09abc9374b0b2fdc023562f99ddada31744e8", "Deleted: sha256:792c379c86dbd2250a7429bc78ef64b9524d9c49c163fa5398092505967ed230", "Deleted: sha256:e7ed01c68431b65f90c923142649429a795ab660e23ea6af15d522ccad753b59", "Deleted: sha256:e722d396f503c712107acad2a081b07e33e73d6286c43f58234f69345a216918"]}

PLAY [Install Profiler Dep] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]
ok: [node0]

TASK [Leave Swarm] *************************************************************
changed: [node1] => {"ansible_job_id": "576494055309.4155", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/576494055309.4155", "started": 1}
changed: [node2] => {"ansible_job_id": "91357437873.36219", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/91357437873.36219", "started": 1}
changed: [node0] => {"ansible_job_id": "236423905425.7922", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/236423905425.7922", "started": 1}

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Init Master] *************************************************************
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather
than running sudo
changed: [node0] => {"changed": true, "cmd": "sudo docker swarm init --advertise-addr 10.10.1.1", "delta": "0:00:02.649507", "end": "2023-09-18 14:08:56.008408", "rc": 0, "start": "2023-09-18 14:08:53.358901", "stderr": "", "stderr_lines": [], "stdout": "Swarm initialized: current node (3w6m8rcfsxi5b7cfjdavh01ru) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-0ymkzg9xnoc93ak77htn5yget2gonet0u1kcqoswecqw3trozk-5411p7z50sumg2tamj7em2oiq 10.10.1.1:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.", "stdout_lines": ["Swarm initialized: current node (3w6m8rcfsxi5b7cfjdavh01ru) is now a manager.", "", "To add a worker to this swarm, run the following command:", "", "    docker swarm join --token SWMTKN-1-0ymkzg9xnoc93ak77htn5yget2gonet0u1kcqoswecqw3trozk-5411p7z50sumg2tamj7em2oiq 10.10.1.1:2377", "", "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions."]}

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Init Workers] ************************************************************
changed: [node1] => {"ansible_job_id": "308481579054.4312", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/308481579054.4312", "started": 1}
changed: [node2] => {"ansible_job_id": "659172197313.36374", "changed": true, "finished": 0, "results_file": "/users/cseas002/.ansible_async/659172197313.36374", "started": 1}

PLAY [Check Status of run] *****************************************************

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node1                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Set uncore frequency] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node1]
ok: [node2]

TASK [Load msr kernel module] **************************************************
changed: [node2] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.004089", "end": "2023-09-18 14:09:05.092900", "rc": 0, "start": "2023-09-18 14:09:05.088811", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "modprobe msr", "delta": "0:00:00.003909", "end": "2023-09-18 14:09:05.097555", "rc": 0, "start": "2023-09-18 14:09:05.093646", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

TASK [Set uncore freq] *********************************************************
changed: [node2] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.003416", "end": "2023-09-18 14:09:05.360712", "rc": 0, "start": "2023-09-18 14:09:05.357296", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
changed: [node1] => {"changed": true, "cmd": "wrmsr -p0 0x620 0x1414", "delta": "0:00:00.003228", "end": "2023-09-18 14:09:05.379494", "rc": 0, "start": "2023-09-18 14:09:05.376266", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY RECAP *********************************************************************
node1                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
node2                      : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Nothing found in stack: microsuite
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_client
Creating service microsuite_bucket
Creating service microsuite_midtier
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_client
Creating service microsuite_bucket
Creating service microsuite_midtier
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_client
Creating service microsuite_bucket
Creating service microsuite_midtier
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_bucket
Creating service microsuite_midtier
Creating service microsuite_client
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_midtier
Creating service microsuite_client
Creating service microsuite_bucket
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
Removing service microsuite_bucket
Removing service microsuite_client
Removing service microsuite_midtier
Removing network microsuite_default
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: No JSON object could be decoded

Syntax Error while loading YAML.
  block sequence entries are not allowed in this context

The error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 35, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  - midtier
  tags:   - run_socwatch
          ^ here
INFO:root:ssh -A node0 hostname
INFO:root:node0.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node1 hostname
INFO:root:node1.hdsearch2.ramp-pg0.wisc.cloudlab.us
INFO:root:ssh -A node2 hostname
INFO:root:node2.hdsearch2.ramp-pg0.wisc.cloudlab.us
Ignoring deprecated options:

expose: Exposing ports is unnecessary - services on the same network can access each other's containers on any port.

Creating network microsuite_default
Creating service microsuite_client
Creating service microsuite_bucket
Creating service microsuite_midtier
Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Run remote profiler] *****************************************************
changed: [node0] => {"changed": true, "cmd": "/users/cseas002/HDSearch-Multinode/scripts/startProfiler.sh /users/cseas002/HDSearch-Multinode/hosts 0", "delta": "0:15:16.821943", "end": "2023-09-18 14:37:27.428707", "rc": 0, "start": "2023-09-18 14:22:10.606764", "stderr": "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\n[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use \n/usr/bin/python3, but is using /usr/bin/python for backward compatibility with \nprior Ansible releases. A future Ansible release will default to using the \ndiscovered platform python for this host. See https://docs.ansible.com/ansible/\n2.9/reference_appendices/interpreter_discovery.html for more information. This \nfeature will be removed in version 2.12. Deprecation warnings can be disabled \nby setting deprecation_warnings=False in ansible.cfg.\nPseudo-terminal will not be allocated because stdin is not a terminal.\r\nssh: Could not resolve hostname cd /users/cseas002/hdsearch-multinode/profiler/; sudo /users/cseas002/hdsearch-multinode/profiler/profiler.sh run_profiler 0 : Name or service not known", "stderr_lines": ["[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node2 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "[DEPRECATION WARNING]: Distribution Ubuntu 18.04 on host node1 should use ", "/usr/bin/python3, but is using /usr/bin/python for backward compatibility with ", "prior Ansible releases. A future Ansible release will default to using the ", "discovered platform python for this host. See https://docs.ansible.com/ansible/", "2.9/reference_appendices/interpreter_discovery.html for more information. This ", "feature will be removed in version 2.12. Deprecation warnings can be disabled ", "by setting deprecation_warnings=False in ansible.cfg.", "Pseudo-terminal will not be allocated because stdin is not a terminal.", "ssh: Could not resolve hostname cd /users/cseas002/hdsearch-multinode/profiler/; sudo /users/cseas002/hdsearch-multinode/profiler/profiler.sh run_profiler 0 : Name or service not known"], "stdout": "/users/cseas002/HDSearch-Multinode/hosts\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nsleep\nnode1\n7376\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node2]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node2] => {\"ansible_job_id\": \"934599714793.8003\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/934599714793.8003\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node2]: FAILED! => {\"ansible_job_id\": \"934599714793.8003\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"7376\"], \"delta\": \"0:00:00.122086\", \"end\": \"2023-09-18 14:37:22.872804\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-09-18 14:37:22.750718\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\nnode2\nnode1\nUsing /etc/ansible/ansible.cfg as config file\n\nPLAY [Run remote profiler] *****************************************************\n\nTASK [Gathering Facts] *********************************************************\nok: [node1]\n\nTASK [Run remote profiler] *****************************************************\nchanged: [node1] => {\"ansible_job_id\": \"119078296812.16631\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/119078296812.16631\", \"started\": 1}\n\nTASK [Check remote profiler] ***************************************************\nfatal: [node1]: FAILED! => {\"ansible_job_id\": \"119078296812.16631\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"15882\"], \"delta\": \"0:00:00.120460\", \"end\": \"2023-09-18 14:37:26.794912\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-09-18 14:37:26.674452\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}\n\nPLAY RECAP *********************************************************************\nnode1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n\n\nnode2", "stdout_lines": ["/users/cseas002/HDSearch-Multinode/hosts", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "sleep", "node1", "7376", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node2]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node2] => {\"ansible_job_id\": \"934599714793.8003\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/934599714793.8003\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node2]: FAILED! => {\"ansible_job_id\": \"934599714793.8003\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"7376\"], \"delta\": \"0:00:00.122086\", \"end\": \"2023-09-18 14:37:22.872804\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-09-18 14:37:22.750718\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node2                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "node2", "node1", "Using /etc/ansible/ansible.cfg as config file", "", "PLAY [Run remote profiler] *****************************************************", "", "TASK [Gathering Facts] *********************************************************", "ok: [node1]", "", "TASK [Run remote profiler] *****************************************************", "changed: [node1] => {\"ansible_job_id\": \"119078296812.16631\", \"changed\": true, \"finished\": 0, \"results_file\": \"/root/.ansible_async/119078296812.16631\", \"started\": 1}", "", "TASK [Check remote profiler] ***************************************************", "fatal: [node1]: FAILED! => {\"ansible_job_id\": \"119078296812.16631\", \"changed\": true, \"cmd\": [\"python3\", \"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\", \"-i\", \"0\", \"-t\", \"15882\"], \"delta\": \"0:00:00.120460\", \"end\": \"2023-09-18 14:37:26.794912\", \"finished\": 1, \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2023-09-18 14:37:26.674452\", \"stderr\": \"Traceback (most recent call last):\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\\n    main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\\n    real_main()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\\n    parse_args()\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\\n    server(args.port,args.perf_iteration,args.process_id)\\n  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\\n    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\\n  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\\n    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\\n    self.server_bind()\\n  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\\n    self.socket.bind(self.server_address)\\nOSError: [Errno 98] Address already in use\", \"stderr_lines\": [\"Traceback (most recent call last):\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 563, in <module>\", \"    main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 554, in main\", \"    real_main()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 551, in real_main\", \"    parse_args()\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 548, in parse_args\", \"    server(args.port,args.perf_iteration,args.process_id)\", \"  File \\\"/users/cseas002/HDSearch-Multinode/profiler/profiler.py\\\", line 433, in server\", \"    server = SimpleXMLRPCServer((hostname, port), allow_none=True)\", \"  File \\\"/usr/lib/python3.6/xmlrpc/server.py\\\", line 599, in __init__\", \"    socketserver.TCPServer.__init__(self, addr, requestHandler, bind_and_activate)\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 456, in __init__\", \"    self.server_bind()\", \"  File \\\"/usr/lib/python3.6/socketserver.py\\\", line 470, in server_bind\", \"    self.socket.bind(self.server_address)\", \"OSError: [Errno 98] Address already in use\"], \"stdout\": \"\", \"stdout_lines\": []}", "", "PLAY RECAP *********************************************************************", "node1                      : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   ", "", "", "node2"]}

PLAY [Kill remote profiler] ****************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(hosts). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tags). Using last defined value only.
[WARNING]: While constructing a mapping from /users/cseas002/HDSearch-
Multinode/ansible/profiler.yml, line 20, column 3, found a duplicate dict key
(tasks). Using last defined value only.

PLAY [Set profiler] ************************************************************

PLAY [Run remote profiler] *****************************************************

PLAY [Kill remote profiler] ****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node2]
ok: [node1]

TASK [Run remote socwatch] *****************************************************
fatal: [node2]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'MONITOR_TIME' is undefined\n\nThe error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 38, column 5, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n  - name: Run remote socwatch\n    ^ here\n"}
fatal: [node1]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'MONITOR_TIME' is undefined\n\nThe error appears to be in '/users/cseas002/HDSearch-Multinode/ansible/profiler.yml': line 38, column 5, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n  - name: Run remote socwatch\n    ^ here\n"}

PLAY RECAP *********************************************************************
node1                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
node2                      : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

Using /users/cseas002/HDSearch-Multinode/ansible.cfg as config file

PLAY [Initialize cluster manager] **********************************************

PLAY [Initialize workers] ******************************************************

PLAY [Check Status of run] *****************************************************

TASK [Gathering Facts] *********************************************************
ok: [node0]

TASK [Check Status] ************************************************************
changed: [node0] => {"changed": true, "cmd": "/users/cseas002/HDSearch-Multinode/scripts/check-run-status.sh", "delta": "0:01:43.755536", "end": "2023-09-18 14:39:18.341265", "rc": 0, "start": "2023-09-18 14:37:34.585729", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

PLAY [Leave Swarm] *************************************************************

PLAY RECAP *********************************************************************
node0                      : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

INFO:root:sudo python3 profiler/profiler.py -n node2 stop
INFO:root:sudo python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 stop
INFO:root:python3: can't open file '/users/cseas002/HDSearch-Multinode/profiler/profiler.py': [Errno 2] No such file or directory
INFO:root:sudo python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node2 report -d /users/cseas002/data/FOURTH_RUN/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=500-0/hdsearch/bucket_node2
INFO:root:python3: can't open file '/users/cseas002/HDSearch-Multinode/profiler/profiler.py': [Errno 2] No such file or directory
INFO:root:sudo python3 /users/cseas002/HDSearch-Multinode/profiler/profiler.py -n node1 report -d /users/cseas002/data/FOURTH_RUN/turbo=False-kernelconfig=baseline-baseline-hyperthreading=False-qps=500-0/hdsearch/midtier_node1
INFO:root:python3: can't open file '/users/cseas002/HDSearch-Multinode/profiler/profiler.py': [Errno 2] No such file or directory
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
INFO:root:./scripts/check-socwatch-status.sh node1
INFO:root:2
